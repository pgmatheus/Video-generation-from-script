{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_2.utilities import get_alpha\n",
    "import cv2\n",
    "import numpy as np\n",
    "alp = get_alpha()\n",
    "\n",
    "original_image_path = './result5.jpg'\n",
    "alpha_image_path = './output_file_location.png'\n",
    "\n",
    "alp.run(original_image_path,alpha_image_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "remove_background(original_image_path, alpha_image_path,'./image_with_background_removed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def merge_audio_inside_folder(audio_root_folder, merged_audio_folder, duration = [0]):\\n    #get all the wav files\\n\\n    audio_clips = []\\n    cont = 0\\n    for dirpath, dirnames, filenames in os.walk(audio_root_folder):\\n        for filename in filenames:\\n            if filename.endswith(\".wav\"):\\n                # Get the full file path\\n                file_path = os.path.join(dirpath, filename)\\n                # Create an AudioFileClip object with the specified duration\\n                if duration[0] == 0:\\n                    audio_clip = AudioFileClip(file_path)\\n                else:\\n                    audio_clip = AudioFileClip(file_path).subclip(0, duration[cont])\\n                audio_clips.append(audio_clip)\\n                cont = cont + 1\\n    final_clip = concatenate_audioclips(audio_clips)\\n\\n    # Write the merged clip to a .wav file\\n    output_path = os.path.join(merged_audio_folder, \"final.wav\")\\n    final_clip.write_audiofile(output_path) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "from moviepy.editor import concatenate_audioclips, AudioFileClip\n",
    "\n",
    "from scripts_2.utilities import merge_audio_inside_folder \"\"\"\n",
    "\n",
    "\"\"\" def merge_audio_inside_folder(audio_root_folder, merged_audio_folder, duration = [0]):\n",
    "    #get all the wav files\n",
    "\n",
    "    audio_clips = []\n",
    "    cont = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(audio_root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".wav\"):\n",
    "                # Get the full file path\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                # Create an AudioFileClip object with the specified duration\n",
    "                if duration[0] == 0:\n",
    "                    audio_clip = AudioFileClip(file_path)\n",
    "                else:\n",
    "                    audio_clip = AudioFileClip(file_path).subclip(0, duration[cont])\n",
    "                audio_clips.append(audio_clip)\n",
    "                cont = cont + 1\n",
    "    final_clip = concatenate_audioclips(audio_clips)\n",
    "\n",
    "    # Write the merged clip to a .wav file\n",
    "    output_path = os.path.join(merged_audio_folder, \"final.wav\")\n",
    "    final_clip.write_audiofile(output_path) \"\"\"\n",
    "    \n",
    "\n",
    "# merge_audio_inside_folder('F:\\\\gg\\\\templates\\\\to_proccess\\\\cursed_doll_test\\\\audio','F:\\\\gg\\\\templates\\\\to_proccess\\\\cursed_doll_test\\\\full', [5,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from scripts_2.utilities import interp_fram\\n\\n\\n\\n\\ninterp_fram.run({\\n       'times_to_interpolate': 2, #multiplier of the frames\\n       'path': 'F:/gg/test_inp', #input folder with pngs\\n       'out_path': 'F:/gg/test_inter', # output folder\\n       'w_o': 512, # width output\\n       'h_o': 512, # height output \\n})\\n \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "from scripts_2.utilities import interp_fram\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import math\n",
    "\n",
    "project_folder = 'F:/gg/templates/to_proccess/cursed_doll_test'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_frames_per_interval(project_path, delay = 0.5, cadence = 4):\n",
    "\n",
    "  durations = []\n",
    "  temp_frames_deforum = []\n",
    "  final_temp_deforum = []\n",
    "\n",
    "\n",
    "  #get durations of each audio\n",
    "  for folder_name in os.listdir(os.path.join(f\"{project_path}\\\\audio\\\\\")):\n",
    "    for filename in os.listdir(os.path.join(f\"{project_path}\\\\audio\\\\{folder_name}\")):\n",
    "      duration = sf.SoundFile(os.path.join(f\"{project_path}\\\\audio\\\\{folder_name}\\\\{filename}\"))\n",
    "      durations.append(duration.frames / duration.samplerate)\n",
    "\n",
    "  #min frames needed\n",
    "  for index, i in enumerate(durations):\n",
    "    temp_val = i + delay\n",
    "    frames_integer_part = round(temp_val*15)\n",
    "    temp_frames_deforum.append(frames_integer_part)\n",
    "\n",
    "  \n",
    "  # calculate the frames needed of each deforum animation\n",
    "  for index in range(len(temp_frames_deforum)):\n",
    "    cont = 0\n",
    "    cond = False    \n",
    "    if os.path.exists(f\"{project_path}\\\\img\\\\{index:07d}\\\\0000000.png\"):\n",
    "        cont = cont + temp_frames_deforum[index]\n",
    "        for index2 in range(index+1,len(temp_frames_deforum)):\n",
    "          if not os.path.exists(f\"{project_path}\\\\img\\\\{index2:07d}\\\\0000000.png\") and cond == False:\n",
    "            cont = cont + temp_frames_deforum[index2]\n",
    "          else:\n",
    "            cond == True\n",
    "        final_temp_deforum.append(cont)\n",
    "    else:\n",
    "      final_temp_deforum.append(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  final_final_deforum = [0] * len(final_temp_deforum)\n",
    "\n",
    "  # recalculate frames for deforum precision\n",
    "  for index, i in enumerate(final_temp_deforum):\n",
    "    \n",
    "    if i != 0:\n",
    "      final_final_deforum[index] = final_temp_deforum[index] + final_temp_deforum[index]%(cadence) + 1\n",
    "    else:\n",
    "      final_final_deforum[index] = 0\n",
    "  srt_frames_needed_adjusted = adjust_subtitles(temp_frames_deforum,final_final_deforum,cadence)\n",
    "  \n",
    "  audio_duration, srt_interval = get_subtitle_times(srt_frames_needed_adjusted)\n",
    "  return final_final_deforum, audio_duration, srt_interval\n",
    "\n",
    "\n",
    "def adjust_subtitles(subtitle, animation, cad):\n",
    "  for index in range(len(subtitle)):\n",
    "    if animation[index] > subtitle[index]:\n",
    "      acc = animation[index]\n",
    "      for index2 in range(index, len(subtitle)):\n",
    "\n",
    "        if acc > subtitle[index2]:\n",
    "          acc = acc - subtitle[index2]\n",
    "        elif acc == subtitle[index2]:\n",
    "          acc = -1\n",
    "        if acc < 2*cad+1 and acc > 0:\n",
    "          subtitle[index2] = subtitle[index2] + acc\n",
    "          acc = -1\n",
    "  return subtitle\n",
    "      \n",
    "def get_subtitle_times(srts, frames = 15, delay = 0.5):\n",
    "  srt_interval = {}\n",
    "  acc = 0\n",
    "  for index, srt_time in enumerate(srts):    \n",
    "    srt_interval[index] = {'start_time': round(acc + delay,3), \"end_time\": round(acc  + srt_time/frames,3)}\n",
    "    acc = acc + srt_time/frames\n",
    "  audio_duration = [round(num/15,3) for num in srts]\n",
    "  return audio_duration, srt_interval\n",
    "  \n",
    "\n",
    "final_final_deforum, audio_duration, srt_interval = get_frames_per_interval(project_folder, 0.65, 4)\n",
    "print(final_final_deforum, audio_duration, srt_interval) \"\"\"\n",
    "\"\"\" print('q')\n",
    "subtitles = [113, 117, 105, 115, 114, 112, 111,256, 249, 251]\n",
    "animations = [337, 0, 0, 115, 114, 223, 0, 256,501,0]\n",
    "\n",
    "adjusted_subtitles = adjust_subtitles(subtitles, animations, 4)\n",
    "print(adjusted_subtitles)  # Output: [113, 117, 107, 115] \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" from scripts_2.utilities import interp_fram\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interp_fram.run({\n",
    "       'times_to_interpolate': 2, #multiplier of the frames\n",
    "       'path': 'F:/gg/test_inp', #input folder with pngs\n",
    "       'out_path': 'F:/gg/test_inter', # output folder\n",
    "       'w_o': 512, # width output\n",
    "       'h_o': 512, # height output \n",
    "})\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n"
     ]
    }
   ],
   "source": [
    "\"\"\" from scripts_2.high_res_img import high_img\n",
    "import torch\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "high_img_f = high_img(4)\n",
    "\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "\n",
    "for file in tqdm(os.listdir('./test_inp/')):\n",
    "\n",
    "    high_img_f.run({\n",
    "    'face': False, # reconstruct face\n",
    "    'path': f'./test_inp/{file}', # image path\n",
    "    'w_i': 480, # width to be resized \n",
    "    'h_i': 270, # height to be resized\n",
    "    'w_o': 1920, # width to be resized \n",
    "    'h_o': 1080, # height to be resized    \n",
    "    'out_path': f'./test/{file}', # image output location\n",
    "    'return_out': 'nothing', # return the data to use later\n",
    "    'show_image': False, # show output\n",
    "}) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "del high_img_f\n",
    "print(torch.cuda.memory_allocated())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
    "\n",
    "# Load the video and audio files\n",
    "video = VideoFileClip(\"f:/f.mp4\")\n",
    "audio = AudioFileClip(\"f:/f.wav\")\n",
    "\n",
    "# Create an audio clip that is the same length as the video\n",
    "audio = audio.set_duration(video.duration)\n",
    "\n",
    "# Merge the video and audio\n",
    "final_clip = video.set_audio(audio)\n",
    "\n",
    "# Write the final clip to a file\n",
    "final_clip.write_videofile(\"f:/m.mp4\", codec=\"libx264\")\n",
    "# Load the two images \"\"\"\n",
    "\n",
    "\"\"\" def resize_image(data):\n",
    "  resized_img = tf.image.resize(\n",
    "  images=data,\n",
    "  # size=[270, 480],     \n",
    "  size=[1080, 1920], \n",
    "  method=tf.image.ResizeMethod.BILINEAR,\n",
    "  preserve_aspect_ratio=False,\n",
    "  antialias=True,\n",
    "  )    \n",
    "  return resized_img\n",
    "\n",
    "img = cv2.imread(\"./z.png\")\n",
    "img = resize_image(img).numpy()\n",
    "#img = cv2.resize(img,(1920,1080))\n",
    "\n",
    "cv2.imwrite(\"007_ma.png\",img) \"\"\"\n",
    "\n",
    "\"\"\" import cv2\n",
    "s_img = cv2.imread(\"F:/gg/templates/hq/a globe inside a jar/0000002/output_0000.png\")\n",
    "s_img = cv2.resize(s_img,(672,378))\n",
    "l_img = cv2.imread(\"D:\\\\Deletar\\\\p_gen\\\\john test\\\\merged\\\\output_0000.png\")\n",
    "x_offset=1150\n",
    "y_offset = 300\n",
    "l_img[y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
    "\n",
    "cv2.imwrite('./test.png', l_img) \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" def merge_gg(s_img,l_img,output,x_offset=1150,y_offset = 300):\n",
    "    s_img = cv2.imread(s_img)\n",
    "    s_img = cv2.resize(s_img,(672,378))\n",
    "    l_img = cv2.imread(l_img)\n",
    "    l_img[y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
    "    cv2.imwrite(output, l_img)\n",
    "\n",
    "for img_path in os.listdir('D:\\\\Deletar\\\\p_gen\\\\john test\\\\merged'):\n",
    "    if img_path[-3:] == 'png':\n",
    "        merge_gg(f\"F:/gg/templates/hq/a globe inside a\n",
    "        jar/0000002/{img_path}\",f\"D:\\\\Deletar\\\\p_gen\\\\john\n",
    "        test\\\\merged\\\\{img_path}\",f\"./test/{img_path}\") \"\"\"\n",
    "\n",
    "print('q')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cb0dd519e46c84f14fc2d0d6172fde6407ecb78b6d95b871c78761f2e6e52fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
