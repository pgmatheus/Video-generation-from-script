{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from scripts_2.utilities import insert_text_img\\n\\n\\nimg = \"./0000000.png\"\\nout = \"./example_image_with_bleeding_text.png\"\\ntext = \\'Untold report: The Cursed  Doll\\'\\ninsert_text_img(img,out, text) '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from PIL import Image, ImageDraw, ImageFont, ImageFilter \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" def insert_text_img(init_img_path, out_img_path, text, img_resize = (1920, 1080), blur_radius = 4, font = \"Chiller.ttf\", font_size = 150, y_offset = 200 ):\n",
    "    # Load the image\n",
    "    img = Image.open(init_img_path)\n",
    "\n",
    "    # Convert the image to RGBA mode\n",
    "    img = img.convert(\"RGBA\")\n",
    "\n",
    "    # Resize the image\n",
    "    img = img.resize(img_resize)\n",
    "\n",
    "    # Create a copy of the image and apply a gaussian blur to it\n",
    "    blur_img = img.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "\n",
    "    # Create a drawing context\n",
    "    draw = ImageDraw.Draw(blur_img)\n",
    "\n",
    "    # Set the font\n",
    "    font = ImageFont.truetype(font, font_size) # Horror-inspired font at 150pt size\n",
    "\n",
    "    # Set the text and color\n",
    "    color = (255, 0, 0) # Blood-red color\n",
    "\n",
    "    # Get the size of the text\n",
    "    text_size = draw.textsize(text, font=font)\n",
    "\n",
    "    # Calculate the position of the text (centered horizontally and slightly above the middle vertically)\n",
    "    x = (img.width - text_size[0]) / 2\n",
    "    y = (img.height - text_size[1]) / 2 - y_offset\n",
    "\n",
    "    # Create a new image for the drop shadow\n",
    "    shadow_img = Image.new(\"RGBA\", img.size, (0, 0, 0, 0))\n",
    "    shadow_draw = ImageDraw.Draw(shadow_img)\n",
    "\n",
    "    # Draw the text with the drop shadow\n",
    "    shadow_draw.text((x+5, y+5), text, font=font, fill=(255, 0, 0, 150))\n",
    "    shadow_draw.text((x, y), text, fill=color, font=font)\n",
    "\n",
    "    # Merge the drop shadow and blurred text images\n",
    "    img = Image.alpha_composite(blur_img, shadow_img)\n",
    "\n",
    "    # Save the image with the red text\n",
    "    img.save(out_img_path) \"\"\"\n",
    "    \n",
    "\"\"\" from scripts_2.utilities import insert_text_img\n",
    "\n",
    "\n",
    "img = \"./0000000.png\"\n",
    "out = \"./example_image_with_bleeding_text.png\"\n",
    "text = 'Untold report: The Cursed  Doll'\n",
    "insert_text_img(img,out, text) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import os\\nimport shutil\\n\\n\\n\\ndirectory = 'F:\\\\gg\\\\output\\\\out'\\n\\n# Get the list of files in the directory\\nfiles = os.listdir(directory)\\n\\n# Sort the list of files in reverse order\\nfiles.sort(reverse=True)\\n\\ncont = len(files)\\nprint(cont)\\n\\nfor file in files:\\n        # Do something with each file\\n        \\n\\n        shutil.copy(f'{directory}/{file}', f'{directory}/output_{cont:07d}.png')\\n        cont = cont + 1\\n\\n \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "directory = 'F:\\\\gg\\\\output\\\\out'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Sort the list of files in reverse order\n",
    "files.sort(reverse=True)\n",
    "\n",
    "cont = len(files)\n",
    "print(cont)\n",
    "\n",
    "for file in files:\n",
    "        # Do something with each file\n",
    "        \n",
    "\n",
    "        shutil.copy(f'{directory}/{file}', f'{directory}/output_{cont:07d}.png')\n",
    "        cont = cont + 1\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from pydub import AudioSegment\\nimport subprocess\\n\\ndef extract_audio_from_video(video_path, output_path):\\n    # Use FFmpeg to convert video to audio\\n    subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'copy', output_path])\\n\\n    print(f'Audio extracted and saved to {output_path} successfully.')\\n\\n# Load the video\\nvideo_path = 'F:/gg/templates/to_proccess/cursed_doll_test/temp/0000000.mp4'\\n\\n\\n\\n\\n\\n# Set output file name and format\\noutput_file = './out_audio.mp3'  # Change the format and file name as needed\\n\\n\\n\\nextract_audio_from_video(video_path, output_file) \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from pydub import AudioSegment\n",
    "import subprocess\n",
    "\n",
    "def extract_audio_from_video(video_path, output_path):\n",
    "    # Use FFmpeg to convert video to audio\n",
    "    subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'copy', output_path])\n",
    "\n",
    "    print(f'Audio extracted and saved to {output_path} successfully.')\n",
    "\n",
    "# Load the video\n",
    "video_path = 'F:/gg/templates/to_proccess/cursed_doll_test/temp/0000000.mp4'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set output file name and format\n",
    "output_file = './out_audio.mp3'  # Change the format and file name as needed\n",
    "\n",
    "\n",
    "\n",
    "extract_audio_from_video(video_path, output_file) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n",
      "6.921814058956916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([415,\n",
       "  813,\n",
       "  0,\n",
       "  340,\n",
       "  824,\n",
       "  0,\n",
       "  634,\n",
       "  0,\n",
       "  1044,\n",
       "  0,\n",
       "  0,\n",
       "  280,\n",
       "  695,\n",
       "  0,\n",
       "  355,\n",
       "  350,\n",
       "  266,\n",
       "  606,\n",
       "  0,\n",
       "  307,\n",
       "  463,\n",
       "  624,\n",
       "  0,\n",
       "  524,\n",
       "  0,\n",
       "  382,\n",
       "  662,\n",
       "  0,\n",
       "  1065,\n",
       "  0,\n",
       "  0,\n",
       "  769,\n",
       "  0,\n",
       "  1058,\n",
       "  0,\n",
       "  0,\n",
       "  712,\n",
       "  0,\n",
       "  0,\n",
       "  355,\n",
       "  2332,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  534,\n",
       "  382,\n",
       "  351,\n",
       "  576,\n",
       "  670,\n",
       "  0,\n",
       "  686,\n",
       "  0,\n",
       "  588,\n",
       "  298,\n",
       "  793,\n",
       "  0,\n",
       "  1216,\n",
       "  0,\n",
       "  0,\n",
       "  433,\n",
       "  600,\n",
       "  745,\n",
       "  0,\n",
       "  400,\n",
       "  624],\n",
       " [6.917,\n",
       "  7.183,\n",
       "  6.367,\n",
       "  5.667,\n",
       "  6.85,\n",
       "  6.883,\n",
       "  5.4,\n",
       "  5.167,\n",
       "  8.017,\n",
       "  3.35,\n",
       "  6.033,\n",
       "  4.667,\n",
       "  5.25,\n",
       "  6.333,\n",
       "  5.917,\n",
       "  5.833,\n",
       "  4.433,\n",
       "  5.65,\n",
       "  4.45,\n",
       "  5.117,\n",
       "  7.717,\n",
       "  5.95,\n",
       "  4.45,\n",
       "  3.35,\n",
       "  5.383,\n",
       "  6.367,\n",
       "  6.95,\n",
       "  4.083,\n",
       "  5.433,\n",
       "  6.633,\n",
       "  5.683,\n",
       "  6.783,\n",
       "  6.033,\n",
       "  6.133,\n",
       "  4.85,\n",
       "  6.65,\n",
       "  3.283,\n",
       "  5.533,\n",
       "  3.05,\n",
       "  5.917,\n",
       "  5.383,\n",
       "  5.367,\n",
       "  7.117,\n",
       "  8.3,\n",
       "  4.883,\n",
       "  7.817,\n",
       "  8.9,\n",
       "  6.367,\n",
       "  5.85,\n",
       "  9.6,\n",
       "  6.033,\n",
       "  5.133,\n",
       "  5.933,\n",
       "  5.5,\n",
       "  9.8,\n",
       "  4.967,\n",
       "  8.45,\n",
       "  4.767,\n",
       "  7.15,\n",
       "  7.7,\n",
       "  5.417,\n",
       "  7.217,\n",
       "  10.0,\n",
       "  5.617,\n",
       "  6.8,\n",
       "  6.667,\n",
       "  10.4],\n",
       " {0: {'start_time': 0, 'end_time': 6.917},\n",
       "  1: {'start_time': 6.917, 'end_time': 14.1},\n",
       "  2: {'start_time': 14.1, 'end_time': 20.467},\n",
       "  3: {'start_time': 20.467, 'end_time': 26.133},\n",
       "  4: {'start_time': 26.133, 'end_time': 32.983},\n",
       "  5: {'start_time': 32.983, 'end_time': 39.867},\n",
       "  6: {'start_time': 39.867, 'end_time': 45.267},\n",
       "  7: {'start_time': 45.267, 'end_time': 50.433},\n",
       "  8: {'start_time': 50.433, 'end_time': 58.45},\n",
       "  9: {'start_time': 58.45, 'end_time': 61.8},\n",
       "  10: {'start_time': 61.8, 'end_time': 67.833},\n",
       "  11: {'start_time': 67.833, 'end_time': 72.5},\n",
       "  12: {'start_time': 72.5, 'end_time': 77.75},\n",
       "  13: {'start_time': 77.75, 'end_time': 84.083},\n",
       "  14: {'start_time': 84.083, 'end_time': 90.0},\n",
       "  15: {'start_time': 90.0, 'end_time': 95.833},\n",
       "  16: {'start_time': 95.833, 'end_time': 100.267},\n",
       "  17: {'start_time': 100.267, 'end_time': 105.917},\n",
       "  18: {'start_time': 105.917, 'end_time': 110.367},\n",
       "  19: {'start_time': 110.367, 'end_time': 115.483},\n",
       "  20: {'start_time': 115.483, 'end_time': 123.2},\n",
       "  21: {'start_time': 123.2, 'end_time': 129.15},\n",
       "  22: {'start_time': 129.15, 'end_time': 133.6},\n",
       "  23: {'start_time': 133.6, 'end_time': 136.95},\n",
       "  24: {'start_time': 136.95, 'end_time': 142.333},\n",
       "  25: {'start_time': 142.333, 'end_time': 148.7},\n",
       "  26: {'start_time': 148.7, 'end_time': 155.65},\n",
       "  27: {'start_time': 155.65, 'end_time': 159.733},\n",
       "  28: {'start_time': 159.733, 'end_time': 165.167},\n",
       "  29: {'start_time': 165.167, 'end_time': 171.8},\n",
       "  30: {'start_time': 171.8, 'end_time': 177.483},\n",
       "  31: {'start_time': 177.483, 'end_time': 184.267},\n",
       "  32: {'start_time': 184.267, 'end_time': 190.3},\n",
       "  33: {'start_time': 190.3, 'end_time': 196.433},\n",
       "  34: {'start_time': 196.433, 'end_time': 201.283},\n",
       "  35: {'start_time': 201.283, 'end_time': 207.933},\n",
       "  36: {'start_time': 207.933, 'end_time': 211.217},\n",
       "  37: {'start_time': 211.217, 'end_time': 216.75},\n",
       "  38: {'start_time': 216.75, 'end_time': 219.8},\n",
       "  39: {'start_time': 219.8, 'end_time': 225.717},\n",
       "  40: {'start_time': 225.717, 'end_time': 231.1},\n",
       "  41: {'start_time': 231.1, 'end_time': 236.467},\n",
       "  42: {'start_time': 236.467, 'end_time': 243.583},\n",
       "  43: {'start_time': 243.583, 'end_time': 251.883},\n",
       "  44: {'start_time': 251.883, 'end_time': 256.767},\n",
       "  45: {'start_time': 256.767, 'end_time': 264.583},\n",
       "  46: {'start_time': 264.583, 'end_time': 273.483},\n",
       "  47: {'start_time': 273.483, 'end_time': 279.85},\n",
       "  48: {'start_time': 279.85, 'end_time': 285.7},\n",
       "  49: {'start_time': 285.7, 'end_time': 295.3},\n",
       "  50: {'start_time': 295.3, 'end_time': 301.333},\n",
       "  51: {'start_time': 301.333, 'end_time': 306.467},\n",
       "  52: {'start_time': 306.467, 'end_time': 312.4},\n",
       "  53: {'start_time': 312.4, 'end_time': 317.9},\n",
       "  54: {'start_time': 317.9, 'end_time': 327.7},\n",
       "  55: {'start_time': 327.7, 'end_time': 332.667},\n",
       "  56: {'start_time': 332.667, 'end_time': 341.117},\n",
       "  57: {'start_time': 341.117, 'end_time': 345.883},\n",
       "  58: {'start_time': 345.883, 'end_time': 353.033},\n",
       "  59: {'start_time': 353.033, 'end_time': 360.733},\n",
       "  60: {'start_time': 360.733, 'end_time': 366.15},\n",
       "  61: {'start_time': 366.15, 'end_time': 373.367},\n",
       "  62: {'start_time': 373.367, 'end_time': 383.367},\n",
       "  63: {'start_time': 383.367, 'end_time': 388.983},\n",
       "  64: {'start_time': 388.983, 'end_time': 395.783},\n",
       "  65: {'start_time': 395.783, 'end_time': 402.45},\n",
       "  66: {'start_time': 402.45, 'end_time': 412.85}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from scripts_2.utilities import interp_fram, get_frames_per_interval\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import math\n",
    "\n",
    "project_folder = 'F:/gg/templates/to_proccess/cursed_doll'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_frames_per_interval(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from scripts_2.utilities import get_alpha\\nimport cv2\\nimport numpy as np\\nalp = get_alpha()\\n\\noriginal_image_path = './result5.jpg'\\nalpha_image_path = './output_file_location.png'\\n\\nalp.run(original_image_path,alpha_image_path) \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from scripts_2.utilities import get_alpha\n",
    "import cv2\n",
    "import numpy as np\n",
    "alp = get_alpha()\n",
    "\n",
    "original_image_path = './result5.jpg'\n",
    "alpha_image_path = './output_file_location.png'\n",
    "\n",
    "alp.run(original_image_path,alpha_image_path) \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def merge_audio_inside_folder(audio_root_folder, merged_audio_folder, duration = [0]):\\n    #get all the wav files\\n\\n    audio_clips = []\\n    cont = 0\\n    for dirpath, dirnames, filenames in os.walk(audio_root_folder):\\n        for filename in filenames:\\n            if filename.endswith(\".wav\"):\\n                # Get the full file path\\n                file_path = os.path.join(dirpath, filename)\\n                # Create an AudioFileClip object with the specified duration\\n                if duration[0] == 0:\\n                    audio_clip = AudioFileClip(file_path)\\n                else:\\n                    audio_clip = AudioFileClip(file_path).subclip(0, duration[cont])\\n                audio_clips.append(audio_clip)\\n                cont = cont + 1\\n    final_clip = concatenate_audioclips(audio_clips)\\n\\n    # Write the merged clip to a .wav file\\n    output_path = os.path.join(merged_audio_folder, \"final.wav\")\\n    final_clip.write_audiofile(output_path) '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "from moviepy.editor import concatenate_audioclips, AudioFileClip\n",
    "\n",
    "from scripts_2.utilities import merge_audio_inside_folder \"\"\"\n",
    "\n",
    "\"\"\" def merge_audio_inside_folder(audio_root_folder, merged_audio_folder, duration = [0]):\n",
    "    #get all the wav files\n",
    "\n",
    "    audio_clips = []\n",
    "    cont = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(audio_root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".wav\"):\n",
    "                # Get the full file path\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                # Create an AudioFileClip object with the specified duration\n",
    "                if duration[0] == 0:\n",
    "                    audio_clip = AudioFileClip(file_path)\n",
    "                else:\n",
    "                    audio_clip = AudioFileClip(file_path).subclip(0, duration[cont])\n",
    "                audio_clips.append(audio_clip)\n",
    "                cont = cont + 1\n",
    "    final_clip = concatenate_audioclips(audio_clips)\n",
    "\n",
    "    # Write the merged clip to a .wav file\n",
    "    output_path = os.path.join(merged_audio_folder, \"final.wav\")\n",
    "    final_clip.write_audiofile(output_path) \"\"\"\n",
    "    \n",
    "\n",
    "# merge_audio_inside_folder('F:\\\\gg\\\\templates\\\\to_proccess\\\\cursed_doll_test\\\\audio','F:\\\\gg\\\\templates\\\\to_proccess\\\\cursed_doll_test\\\\full', [5,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from scripts_2.utilities import interp_fram\\n\\n\\n\\n\\ninterp_fram.run({\\n       'times_to_interpolate': 2, #multiplier of the frames\\n       'path': 'F:/gg/test_inp', #input folder with pngs\\n       'out_path': 'F:/gg/test_inter', # output folder\\n       'w_o': 512, # width output\\n       'h_o': 512, # height output \\n})\\n \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import os\n",
    "from scripts_2.utilities import interp_fram\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import math\n",
    "\n",
    "project_folder = 'F:/gg/templates/to_proccess/cursed_doll_test'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_frames_per_interval(project_path, delay = 0.5, cadence = 4):\n",
    "\n",
    "  durations = []\n",
    "  temp_frames_deforum = []\n",
    "  final_temp_deforum = []\n",
    "\n",
    "\n",
    "  #get durations of each audio\n",
    "  for folder_name in os.listdir(os.path.join(f\"{project_path}\\\\audio\\\\\")):\n",
    "    for filename in os.listdir(os.path.join(f\"{project_path}\\\\audio\\\\{folder_name}\")):\n",
    "      duration = sf.SoundFile(os.path.join(f\"{project_path}\\\\audio\\\\{folder_name}\\\\{filename}\"))\n",
    "      durations.append(duration.frames / duration.samplerate)\n",
    "\n",
    "  #min frames needed\n",
    "  for index, i in enumerate(durations):\n",
    "    temp_val = i + delay\n",
    "    frames_integer_part = round(temp_val*15)\n",
    "    temp_frames_deforum.append(frames_integer_part)\n",
    "\n",
    "  \n",
    "  # calculate the frames needed of each deforum animation\n",
    "  for index in range(len(temp_frames_deforum)):\n",
    "    cont = 0\n",
    "    cond = False    \n",
    "    if os.path.exists(f\"{project_path}\\\\img\\\\{index:07d}\\\\0000000.png\"):\n",
    "        cont = cont + temp_frames_deforum[index]\n",
    "        for index2 in range(index+1,len(temp_frames_deforum)):\n",
    "          if not os.path.exists(f\"{project_path}\\\\img\\\\{index2:07d}\\\\0000000.png\") and cond == False:\n",
    "            cont = cont + temp_frames_deforum[index2]\n",
    "          else:\n",
    "            cond == True\n",
    "        final_temp_deforum.append(cont)\n",
    "    else:\n",
    "      final_temp_deforum.append(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  final_final_deforum = [0] * len(final_temp_deforum)\n",
    "\n",
    "  # recalculate frames for deforum precision\n",
    "  for index, i in enumerate(final_temp_deforum):\n",
    "    \n",
    "    if i != 0:\n",
    "      final_final_deforum[index] = final_temp_deforum[index] + final_temp_deforum[index]%(cadence) + 1\n",
    "    else:\n",
    "      final_final_deforum[index] = 0\n",
    "  srt_frames_needed_adjusted = adjust_subtitles(temp_frames_deforum,final_final_deforum,cadence)\n",
    "  \n",
    "  audio_duration, srt_interval = get_subtitle_times(srt_frames_needed_adjusted)\n",
    "  return final_final_deforum, audio_duration, srt_interval\n",
    "\n",
    "\n",
    "def adjust_subtitles(subtitle, animation, cad):\n",
    "  for index in range(len(subtitle)):\n",
    "    if animation[index] > subtitle[index]:\n",
    "      acc = animation[index]\n",
    "      for index2 in range(index, len(subtitle)):\n",
    "\n",
    "        if acc > subtitle[index2]:\n",
    "          acc = acc - subtitle[index2]\n",
    "        elif acc == subtitle[index2]:\n",
    "          acc = -1\n",
    "        if acc < 2*cad+1 and acc > 0:\n",
    "          subtitle[index2] = subtitle[index2] + acc\n",
    "          acc = -1\n",
    "  return subtitle\n",
    "      \n",
    "def get_subtitle_times(srts, frames = 15, delay = 0.5):\n",
    "  srt_interval = {}\n",
    "  acc = 0\n",
    "  for index, srt_time in enumerate(srts):    \n",
    "    srt_interval[index] = {'start_time': round(acc + delay,3), \"end_time\": round(acc  + srt_time/frames,3)}\n",
    "    acc = acc + srt_time/frames\n",
    "  audio_duration = [round(num/15,3) for num in srts]\n",
    "  return audio_duration, srt_interval\n",
    "  \n",
    "\n",
    "final_final_deforum, audio_duration, srt_interval = get_frames_per_interval(project_folder, 0.65, 4)\n",
    "print(final_final_deforum, audio_duration, srt_interval) \"\"\"\n",
    "\"\"\" print('q')\n",
    "subtitles = [113, 117, 105, 115, 114, 112, 111,256, 249, 251]\n",
    "animations = [337, 0, 0, 115, 114, 223, 0, 256,501,0]\n",
    "\n",
    "adjusted_subtitles = adjust_subtitles(subtitles, animations, 4)\n",
    "print(adjusted_subtitles)  # Output: [113, 117, 107, 115] \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" from scripts_2.utilities import interp_fram\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interp_fram.run({\n",
    "       'times_to_interpolate': 2, #multiplier of the frames\n",
    "       'path': 'F:/gg/test_inp', #input folder with pngs\n",
    "       'out_path': 'F:/gg/test_inter', # output folder\n",
    "       'w_o': 512, # width output\n",
    "       'h_o': 512, # height output \n",
    "})\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n"
     ]
    }
   ],
   "source": [
    "\"\"\" from scripts_2.high_res_img import high_img\n",
    "import torch\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "high_img_f = high_img(4)\n",
    "\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "\n",
    "for file in tqdm(os.listdir('./test_inp/')):\n",
    "\n",
    "    high_img_f.run({\n",
    "    'face': False, # reconstruct face\n",
    "    'path': f'./test_inp/{file}', # image path\n",
    "    'w_i': 480, # width to be resized \n",
    "    'h_i': 270, # height to be resized\n",
    "    'w_o': 1920, # width to be resized \n",
    "    'h_o': 1080, # height to be resized    \n",
    "    'out_path': f'./test/{file}', # image output location\n",
    "    'return_out': 'nothing', # return the data to use later\n",
    "    'show_image': False, # show output\n",
    "}) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "del high_img_f\n",
    "print(torch.cuda.memory_allocated())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
    "\n",
    "# Load the video and audio files\n",
    "video = VideoFileClip(\"f:/f.mp4\")\n",
    "audio = AudioFileClip(\"f:/f.wav\")\n",
    "\n",
    "# Create an audio clip that is the same length as the video\n",
    "audio = audio.set_duration(video.duration)\n",
    "\n",
    "# Merge the video and audio\n",
    "final_clip = video.set_audio(audio)\n",
    "\n",
    "# Write the final clip to a file\n",
    "final_clip.write_videofile(\"f:/m.mp4\", codec=\"libx264\")\n",
    "# Load the two images \"\"\"\n",
    "\n",
    "\"\"\" def resize_image(data):\n",
    "  resized_img = tf.image.resize(\n",
    "  images=data,\n",
    "  # size=[270, 480],     \n",
    "  size=[1080, 1920], \n",
    "  method=tf.image.ResizeMethod.BILINEAR,\n",
    "  preserve_aspect_ratio=False,\n",
    "  antialias=True,\n",
    "  )    \n",
    "  return resized_img\n",
    "\n",
    "img = cv2.imread(\"./z.png\")\n",
    "img = resize_image(img).numpy()\n",
    "#img = cv2.resize(img,(1920,1080))\n",
    "\n",
    "cv2.imwrite(\"007_ma.png\",img) \"\"\"\n",
    "\n",
    "\"\"\" import cv2\n",
    "s_img = cv2.imread(\"F:/gg/templates/hq/a globe inside a jar/0000002/output_0000.png\")\n",
    "s_img = cv2.resize(s_img,(672,378))\n",
    "l_img = cv2.imread(\"D:\\\\Deletar\\\\p_gen\\\\john test\\\\merged\\\\output_0000.png\")\n",
    "x_offset=1150\n",
    "y_offset = 300\n",
    "l_img[y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
    "\n",
    "cv2.imwrite('./test.png', l_img) \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" def merge_gg(s_img,l_img,output,x_offset=1150,y_offset = 300):\n",
    "    s_img = cv2.imread(s_img)\n",
    "    s_img = cv2.resize(s_img,(672,378))\n",
    "    l_img = cv2.imread(l_img)\n",
    "    l_img[y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
    "    cv2.imwrite(output, l_img)\n",
    "\n",
    "for img_path in os.listdir('D:\\\\Deletar\\\\p_gen\\\\john test\\\\merged'):\n",
    "    if img_path[-3:] == 'png':\n",
    "        merge_gg(f\"F:/gg/templates/hq/a globe inside a\n",
    "        jar/0000002/{img_path}\",f\"D:\\\\Deletar\\\\p_gen\\\\john\n",
    "        test\\\\merged\\\\{img_path}\",f\"./test/{img_path}\") \"\"\"\n",
    "\n",
    "print('q')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cb0dd519e46c84f14fc2d0d6172fde6407ecb78b6d95b871c78761f2e6e52fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
