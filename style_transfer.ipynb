{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from skimage import exposure\n",
    "\n",
    "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
    "hub_handle = \"./magenta_arbitrary-image-stylization-v1-256_2\"\n",
    "hub_module = hub.load(hub_handle)\n",
    "\n",
    "EXTERNAL = True\n",
    "\n",
    "if EXTERNAL:\n",
    "  %store -r WIDTH\n",
    "  %store -r HEIGHT\n",
    "  %store -r TEXT\n",
    "  %store -r VISUALIZE\n",
    "  %store -r SAVE_FOLDER\n",
    "  %store -r PROJECT_NAME\n",
    "  %store -r SHOW_OUTPUT\n",
    "  %store -r IMG_NUMBER\n",
    "  %store -r THUMBNAIL\n",
    " \n",
    "\n",
    "else:\n",
    "  WIDTH = 768\n",
    "  HEIGHT = 768\n",
    "  VISUALIZE = True  \n",
    "  SAVE_FOLDER = \"D:\\\\Deletar\\\\p_gen\"\n",
    "  PROJECT_NAME = \"THE FELLOWSHIP OF THE RING\"\n",
    "  STYLES_FOLDER = \".\\\\styles\"\n",
    "  SHOW_OUTPUT = True\n",
    "  IMG_NUMBER = 2\n",
    "  \n",
    "  \n",
    "\n",
    "project_folder = f\"{SAVE_FOLDER}\\\\{PROJECT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(image):\n",
    "  \"\"\"Returns a cropped square image.\"\"\"\n",
    "  shape = image.shape\n",
    "  new_shape = min(shape[1], shape[2])\n",
    "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
    "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
    "  image = tf.image.crop_to_bounding_box(\n",
    "      image, offset_y, offset_x, new_shape, new_shape)\n",
    "  return image\n",
    "\n",
    "\n",
    "\"\"\" def load_image(image_url, image_size=(256, 256),\n",
    "preserve_aspect_ratio=True): \"\"\"\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def load_image(image_url, image_size):\n",
    "  \"\"\"Loads and preprocesses images.\"\"\"\n",
    "  # Cache image file locally.\n",
    "  \"\"\" image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url) \"\"\"\n",
    "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "  img = tf.io.decode_image(\n",
    "      tf.io.read_file(image_url),\n",
    "      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
    "  \"\"\" img = crop_center(img) \"\"\"\n",
    "  img = tf.image.resize(img, image_size, antialias=True)\n",
    "  return img\n",
    "\n",
    "# @title Load example images  { display-mode: \"form\" }\n",
    "\n",
    "\n",
    "# The content image size can be arbitrary.\n",
    "\n",
    "# The style prediction model was trained with image size 256 and it's the \n",
    "# recommended image size for the style image (though, other sizes work as \n",
    "# well but will lead to different results).\n",
    "style_img_size = (256, 256)  # Recommended to keep it at 256.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_img_mod = []\n",
    "style_name = []\n",
    "for img in os.listdir(STYLES_FOLDER):\n",
    "    style_name.append(img)\n",
    "    temp_img = load_image(f\"{STYLES_FOLDER}\\\\{img}\", style_img_size)\n",
    "    style_img_mod.append(tf.nn.avg_pool(temp_img, ksize=[3,3], strides=[1,1], padding='SAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "if EXTERNAL:\n",
    "    if (not os.path.exists(f\"{project_folder}\\\\style\\\\\")):\n",
    "        os.makedirs(f\"{project_folder}\\\\style\\\\\")\n",
    "    for folder_name in os.listdir(os.path.join(f\"{project_folder}\\\\img\\\\\")):\n",
    "        print(folder_name)\n",
    "        for filename in os.listdir(os.path.join(f\"{project_folder}\\\\img\\\\{folder_name}\")):\n",
    "            if (not os.path.exists(f\"{project_folder}\\\\style\\\\{folder_name}\")):\n",
    "                    os.makedirs(f\"{project_folder}\\\\style\\\\{folder_name}\")\n",
    "            if (filename == \"c.jpg\"):\n",
    "                content_image = load_image(os.path.join(f\"{project_folder}\\\\img\\\\{folder_name}\\\\{filename}\"), (HEIGHT, WIDTH))\n",
    "                tf.keras.preprocessing.image.save_img(f\"{project_folder}\\\\style\\\\{folder_name}\\\\c.jpg\",content_image[0])\n",
    "                for i, dif_style in enumerate(style_img_mod):\n",
    "                    outputs = hub_module(tf.constant(content_image), tf.constant(dif_style))\n",
    "                    stylized_image = outputs[0][0]\n",
    "                    \n",
    "                    # stylized_image = exposure.equalize_hist(stylized_image*255)*255                    \n",
    "                    tf.keras.preprocessing.image.save_img(f\"{project_folder}\\\\style\\\\{folder_name}\\\\result_a{i}.jpg\",stylized_image)\n",
    "else:\n",
    "    content_image_url = 'D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\c.jpg'  # @param {type:\"string\"}\n",
    "    content_image = load_image(content_image_url, (WIDTH, HEIGHT))\n",
    "\n",
    "    for i, dif_style in enumerate(style_img_mod):\n",
    "        print(style_name[i])\n",
    "        outputs = hub_module(tf.constant(content_image), tf.constant(dif_style))\n",
    "        stylized_image = outputs[0][0]    \n",
    "        tf.keras.preprocessing.image.save_img(f\"result_a{i}.jpg\",stylized_image)\n",
    "        plt.imshow(stylized_image) \n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cb0dd519e46c84f14fc2d0d6172fde6407ecb78b6d95b871c78761f2e6e52fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
