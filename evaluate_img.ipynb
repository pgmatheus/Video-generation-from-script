{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "TRAIN_EVALUATE_IMG = True\n",
    "\n",
    "EXTERNAL = False\n",
    "\n",
    "if EXTERNAL:\n",
    "  %store -r TEXT\n",
    "  %store -r VISUALIZE\n",
    "  %store -r SAVE_FOLDER\n",
    "  %store -r PROJECT_NAME\n",
    "  %store -r SHOW_OUTPUT\n",
    "  %store -r IMG_NUMBER\n",
    "  %store -r THUMBNAIL\n",
    "else:  \n",
    "  VISUALIZE = True  \n",
    "  SAVE_FOLDER = \"D:\\\\Deletar\\\\p_gen\"\n",
    "  PROJECT_NAME = \"THE FELLOWSHIP OF THE RING\"\n",
    "  STYLES_FOLDER = \".\\\\styles\"\n",
    "  SHOW_OUTPUT = True\n",
    "  IMG_NUMBER = 2\n",
    "\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "265/265 [==============================] - 12s 37ms/step - loss: 0.1835 - accuracy: 0.0058 - val_loss: 0.2100 - val_accuracy: 0.0040\n",
      "Epoch 2/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1639 - accuracy: 0.0061 - val_loss: 0.1717 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1702 - accuracy: 0.0067 - val_loss: 0.2566 - val_accuracy: 0.0040\n",
      "Epoch 4/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1616 - accuracy: 0.0061 - val_loss: 0.1774 - val_accuracy: 0.0010\n",
      "Epoch 5/100\n",
      "265/265 [==============================] - 10s 37ms/step - loss: 0.1567 - accuracy: 0.0058 - val_loss: 0.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1620 - accuracy: 0.0065 - val_loss: 0.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1619 - accuracy: 0.0053 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1565 - accuracy: 0.0069 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1700 - accuracy: 0.0060 - val_loss: 0.1746 - val_accuracy: 0.0010\n",
      "Epoch 10/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1577 - accuracy: 0.0061 - val_loss: 0.1662 - val_accuracy: 0.0020\n",
      "Epoch 11/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1552 - accuracy: 0.0065 - val_loss: 0.1937 - val_accuracy: 0.0040\n",
      "Epoch 12/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1663 - accuracy: 0.0060 - val_loss: 0.1688 - val_accuracy: 0.0010\n",
      "Epoch 13/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1577 - accuracy: 0.0070 - val_loss: 0.2096 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "265/265 [==============================] - 10s 36ms/step - loss: 0.1539 - accuracy: 0.0074 - val_loss: 0.1678 - val_accuracy: 0.0010\n",
      "Epoch 15/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1593 - accuracy: 0.0064 - val_loss: 0.2059 - val_accuracy: 0.0040\n",
      "Epoch 16/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1567 - accuracy: 0.0066 - val_loss: 0.1791 - val_accuracy: 0.0030\n",
      "Epoch 17/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1753 - accuracy: 0.0070 - val_loss: 0.1735 - val_accuracy: 0.0040\n",
      "Epoch 18/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1574 - accuracy: 0.0070 - val_loss: 0.1769 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "265/265 [==============================] - 10s 35ms/step - loss: 0.1574 - accuracy: 0.0074 - val_loss: 0.2238 - val_accuracy: 0.0040\n",
      "Epoch 20/100\n",
      " 65/265 [======>.......................] - ETA: 6s - loss: 0.1565 - accuracy: 0.0077"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 84\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m\"\"\" model.add(tf.keras.layers.Dense(128, activation='relu'))\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39mmodel.add(tf.keras.layers.Dropout(0.5)) \"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 84\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset\u001b[39m.\u001b[39;49mbatch(\u001b[39m32\u001b[39;49m)\u001b[39m.\u001b[39;49mshuffle(\u001b[39m100\u001b[39;49m), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mdataset2\u001b[39m.\u001b[39;49mbatch(\u001b[39m32\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def decode_image(image_name):\n",
    "    image = tf.io.read_file(\"D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\images\\\\\" + image_name)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (WIDTH,HEIGHT), antialias=True)    \n",
    "    return image\n",
    "\n",
    "if TRAIN_EVALUATE_IMG:    \n",
    "    dtrain = pd.read_csv('D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\data\\\\train.csv', encoding='latin-1')\n",
    "    image_names = dtrain['ImageFile'].to_list()\n",
    "    image_names = tf.convert_to_tensor(image_names, dtype=tf.string)\n",
    "\n",
    "    dtrain['score'] = tf.cast(dtrain['score'],dtype=tf.float32)  \n",
    "    \n",
    "    sco_arr = []\n",
    "    for i in dtrain['score']:        \n",
    "            temp_str = tf.cast(i,dtype=tf.float32)\n",
    "            sco_arr.append(temp_str)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_names, sco_arr))\n",
    "    dataset = dataset.map(lambda x, y: (decode_image(x), y))\n",
    "\n",
    "      # Normalize images\n",
    "    dataset = dataset.map(lambda x, y: (x / 255.0, y))\n",
    "\n",
    "    dtest = pd.read_csv('D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\data\\\\test.csv', encoding='latin-1')\n",
    "    image_names = dtest['ImageFile'].to_list()\n",
    "    image_names = tf.convert_to_tensor(image_names, dtype=tf.string)\n",
    "\n",
    "    dtest['score'] = tf.cast(dtest['score'],dtype=tf.float32)  \n",
    "    \n",
    "    sco_arr = []\n",
    "    for i in dtest['score']:        \n",
    "            temp_str = tf.cast(i,dtype=tf.float32)\n",
    "            sco_arr.append(temp_str)\n",
    "\n",
    "    dataset2 = tf.data.Dataset.from_tensor_slices((image_names, sco_arr))\n",
    "    dataset2 = dataset2.map(lambda x, y: (decode_image(x), y))\n",
    "\n",
    "      # Normalize images\n",
    "    dataset2 = dataset2.map(lambda x, y: (x / 255.0, y))\n",
    "         \n",
    "\n",
    "    # Create a simple model \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(WIDTH,HEIGHT,3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(1, )\n",
    "    ])\n",
    "    \"\"\" model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(WIDTH, HEIGHT, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ]) \"\"\"\n",
    "    \"\"\" initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, 4, padding='same', strides=2, kernel_initializer=initializer, use_bias=False,),)\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    model.add(tf.keras.layers.Conv2D(64, 4, padding='same', strides=2, kernel_initializer=initializer, use_bias=False,),)    \n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    model.add(tf.keras.layers.Conv2D(64, 4, padding='same', strides=2, kernel_initializer=initializer, use_bias=False,),)    \n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    model.add(tf.keras.layers.Conv2D(64, 4, padding='same', strides=2, kernel_initializer=initializer, use_bias=False,),)    \n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Flatten()) \"\"\"\n",
    "    \"\"\" model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5)) \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    model.compile(optimizer='Adam', loss='MAE', metrics=['accuracy'])\n",
    "    model.fit(dataset.batch(32).shuffle(100), epochs=100, validation_data=dataset2.batch(32))\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50036323]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1adc07a17f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyFUlEQVR4nO3de3SU5bk28GtmMjM5TwghJxIgHAQ5BCuFmKqIghxaLSq7Gw/dReunnza4qmxPaeuxh1i7dqW1iHvvWqifIkoruKUVqyihtoASSRHRSDCQQA6QQGZymkky83x/uEh3FOS+IeFJwvVba9YimYs7zzvvO3Pnzczc4zDGGBAREZ1hTtsLICKisxMbEBERWcEGREREVrABERGRFWxARERkBRsQERFZwQZERERWsAEREZEVUbYX8HmRSATV1dVISEiAw+GwvRwiIlIyxqCpqQmZmZlwOk98ntPnGlB1dTWys7NtL4OIiE5TVVUVsrKyTnh9rzWgZcuW4Re/+AVqa2sxefJkPPnkk5g2bdpJ/19CQgIA4MGf/Q+io+NEPyvKJT9Tcjp1Z1VOl/yvlNozti/7zeCLxXV/LdXUdmnWAcCpuL0BIMqtWIvyiNTc5spdr7rJlTchXLo4HC75xCyX9i8HEXnUKEtHO8Pi7NfCVara69qGi7P1dc2q2tGtDap8jFO+Rw8erNHVzhghzu4+WKeq3aJ4FmZsRrI4Gwq24j8e/VbX4/mJ9EoDevHFF7FkyRI8/fTTyMvLw9KlSzFnzhyUlZUhNTX1S//vsQeU6Og4RMfEi36e+2xoQNom0YcakLuvNCBlk+jdBqS7DR0ueZdwKX9ZQUTe3IzyGI9xdoqziWHZL5zHxDpkjw8AEBOjKo3oSFC3Fpe8AUV7dYuR/iIOAB5vrKp2u6IBadZxzMnun73yIoRf/vKXuOWWW3DTTTdh/PjxePrppxEbG4vf/e53vfHjiIioH+rxBtTe3o6SkhLMmjXrnz/E6cSsWbOwZcuWL+RDoRACgUC3CxERDXw93oDq6+sRDoeRlpbW7ftpaWmora39Qr6oqAg+n6/rwhcgEBGdHay/D6iwsBB+v7/rUlWleyKSiIj6px5/EUJKSgpcLhfq6rq/GqOurg7p6elfyHu9Xni93p5eBhER9XE9fgbk8XgwZcoUbNy4set7kUgEGzduRH5+fk//OCIi6qd65WXYS5YswaJFi/DVr34V06ZNw9KlS9HS0oKbbrqpN34cERH1Q73SgBYuXIjDhw/jwQcfRG1tLc477zxs2LDhCy9MICKis5fDGCN/F9oZEAgE4PP58N/PFCM2VvhGVMWbS11Rur86at5251K8GQ1QvtFR+yZXxVqilOtW34YO+SHmjlJOWVANk9Ad6i6H/HZRvakYgBftqnzdvgPibMbIoaraEcW7f90R3XY2trSKsx6vR1Xb0xESZ2Ocutt7135VHJX1TeLs7n26aQVtiv2TkZOiql3md4uzEYd8HR3BZqx/+FL4/X4kJiaeMGf9VXBERHR2YgMiIiIr2ICIiMgKNiAiIrKCDYiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK3plFlxPyPQ5ERcn649RLnkfdSjGqwCAgXx8y8k+//zznIpZPMrScCo2MypKN6ImKtypyh+ubRBnXR7dOJaYJPkokbh4XW13VEScPXLwix+2+GXa2nS3YWK8/CNLjNHVdrvlDwOxirFXALDPHxZnU+N1tTvcMeKs6dB95Ms53gpVfoSrTJyde0muqvbuZnm2rFl+zALAJOMXZxtC8uOqPSgbwcQzICIisoINiIiIrGADIiIiK9iAiIjICjYgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKCDYiIiKxgAyIiIiv67Cy4tEQn4oWz4HR0c7KMUazB6GaqGcXoK4dDuatc8rVEaY8CxQw7ABg5Jk2cdSnWDQBrX/qjOLvwX69Q1XZHy7czcWymqraJhFT5QMMRcXZQsqo02vzt4myTPAoAyIrtEGfTIk2q2u1h+WLig7rbG2m6mZG7DqWLs01HZXPSjqn1y+8TSVkZqtojxwwVZ8MN8rlxra3N+E9BjmdARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRVsQEREZAUbEBERWdFnR/G42zvhccvG5jgUI3Baj7ao1mGi5fNyXB268R3BoHwt9Q1tqtoOt3zdKWnyUTkA0HC0WpUf95Xx4myUM6Kq/foLL4qzCxd+XVXb0dQgzoaUI54GJcWq8vFZg8XZTuiOw9YX7hZnyz1xqtqjLvqeOBs7OVtV2+2RH+NNIbeqdkNLWJUfdJF85FBMOKCqPTYgH4FTW7ZDVTu0Tz4WaH+LfN1RwaAoxzMgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKCDYiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK/rsLLj60nfRFh0jygYa5bOSHMajWkdHMCTOOjuVs+CMfO6Zx+dT1fYmymd2mTjdYZDuS1Ll68oqxNnYBK+qtr9FPk8vqll+nABAfKLs+AOAuGjdrLEP1m1Q5SdfPlOcjTQcUdX+/g75LMUHJslnngFAarp8f9bsKFfV7ojI57WFWmSzyY6JidHtz6Zm+ePEkY52Ve2M8yeJs77LdfP0EuPkj4eDAvK5cU1NzcDPHj1pjmdARERkRY83oIcffhgOh6PbZdy4cT39Y4iIqJ/rlT/BTZgwAW+++eY/f0hUn/1LHxERWdIrnSEqKgrp6em9UZqIiAaIXnkOaM+ePcjMzMTIkSNxww03oLKy8oTZUCiEQCDQ7UJERANfjzegvLw8rFy5Ehs2bMDy5ctRUVGBiy++GE1NTcfNFxUVwefzdV2ys3Wv4iAiov6pxxvQvHnz8K1vfQu5ubmYM2cO/vznP6OxsREvvfTScfOFhYXw+/1dl6qqqp5eEhER9UG9/uqApKQknHPOOSgvP/5r/L1eL7xe3Xs/iIio/+v19wE1Nzdj7969yMjI6O0fRURE/UiPN6C7774bxcXF2LdvH/7+97/j6quvhsvlwnXXXdfTP4qIiPqxHv8T3IEDB3DdddehoaEBQ4YMwUUXXYStW7diyJAhqjpfvTQLifGxsrAZIa4bNp2qdTi98vE68oEmn+lsk4/icTh0I4SMkY8SOVTdrKodbpGP5ACA5PhocTbUqhtT8q2vfVWcvWHhtaraf/jTanG2qeyAqvYdS59T5c9fu1WcfezhG1W1U+sPibOlh3V/yXC9/6E4G47ojsOoKPl9whmW39cAoKNNd39zd8qP2yj5BCEAQMuWzeJsYqL8vgYAR50OcdblkLcLV2ubKNfjDWj1avmdloiIzl6cBUdERFawARERkRVsQEREZAUbEBERWcEGREREVrABERGRFWxARERkBRsQERFZwQZERERWsAEREZEVvf5xDKfKhAIw7g5ZVjH+yOnUzXiCkc9KcsijAAB3nHzOHJQz7OCU79qh45S/h7h0t6FihBTgTlDVvqJuojgbH6sbwvXfj9wjzs7/xjWq2kcjLap8YvvxP9DxeOqadNtpFLP9Ftz8L6ra7iz5nTMqNkZVO9Ihv8M5Y3Qz0sKK2gDgdMnvy44oXe2wYg6kS/n45uiQP65EOuTHSaBJNouSZ0BERGQFGxAREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVrABERGRFWxARERkBRsQERFZ0WdH8QQ7x8HTES/KuiK14rrudt06TLBBHg4nqmo7o4PysFs22uKYSLR81IvDqxsNYrzKcUZueT4clo+cAYBPKz4SZxctuEBV+9n1suMPAObc9zNV7e9PuUiVr/6kVJx95YFlqtrDh48UZ10O3R3I7YkTZzv3Nqpq/+x3r4mzP7j5clXtkHL0VZzXJ86azmZVbceRRnG2LRBS1Y4O+MXZoFN+vhJsk62DZ0BERGQFGxAREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVrABERGRFWxARERkBRsQERFZwQZERERW9NlZcNc/ugZRUV5RNmzkffTaa69TrcNEpcmznWFVbU06yjtIVXv/oT3i7KG6VlXtSGdElY+Plc/VGpUmv70B4DszLxRn6+t0c8w+OnxAnD0vI0dV+1/+7zdV+T/9vF6c/dq/jVDVTnlbPk/v8Yd+qqr9ox9+Wx4O6+4/V44bIc46gkdUtWMiut/NTVOjPNyunAWnGL0YHae7bzo75PMoPZ3yOXMel+y+xjMgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKCDYiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK/rsLLjG4EG4otyirMstywHAC3/6rWodBvI5Zu6IfB0AEGhsEmfHj5moqr2/Zp842+TUHQbJw8aq8mF3ujyboJt553Yli7Mxo3Szxr4xUl7bkXuuqrbba1T5FLd8H8XEJKpqfxSQz7y7657bVbX9wy8SZ/e/tk9V+6UXfiLORk16SlW7s2OIKj9hiHz/eAKfqmrDyB+DOqNdqtKtcW3irMctn6UYaW0DsOqkOZ4BERGRFeoGtHnzZlx55ZXIzMyEw+HAunXrul1vjMGDDz6IjIwMxMTEYNasWdizRz6ZmYiIzg7qBtTS0oLJkydj2bJlx73+8ccfx69//Ws8/fTT2LZtG+Li4jBnzhwEg/Kx30RENPCpnwOaN28e5s2bd9zrjDFYunQpfvSjH2H+/PkAgGeffRZpaWlYt24drr322tNbLRERDRg9+hxQRUUFamtrMWvWrK7v+Xw+5OXlYcuWLcf9P6FQCIFAoNuFiIgGvh5tQLW1tQCAtM99qmVaWlrXdZ9XVFQEn8/XdcnOzu7JJRERUR9l/VVwhYWF8Pv9XZeqqirbSyIiojOgRxtQevpn7/eoq6vr9v26urqu6z7P6/UiMTGx24WIiAa+Hm1AOTk5SE9Px8aNG7u+FwgEsG3bNuTn5/fkjyIion5O/Sq45uZmlJeXd31dUVGB0tJSJCcnY9iwYbjzzjvxk5/8BGPGjEFOTg4eeOABZGZm4qqrrurJdRMRUT+nbkDbt2/HpZde2vX1kiVLAACLFi3CypUrce+996KlpQW33norGhsbcdFFF2HDhg2Ijo5W/ZwwGsTLaw50iOtecp5upM1f/3FEnI0dpNvGlvbD4mzpJ7pXB8bGysfOjM/IUNUekxFR5f+06TlxdktJvKp2zNLrxdlIRDeK5/2QQ5yNKi9V1R4xKVOVv+jS88TZ2Gz5CCEA2Jk+XpyNjtaNm9p062Jx9sILp6pqz2mR/wEn+f31qtqPf6wbadPYJj9WnEZ3/8lKl98/nQ7diKedu/4hzsbHxIqz7Z2ysT3qBjRjxgwYc+KNdDgcePTRR/Hoo49qSxMR0VnE+qvgiIjo7MQGREREVrABERGRFWxARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFaoR/GcKc2tbXC5ZMu7Yubl4rpbdu1WraM9HBRnq2paVbXHDJHPJjOHO1W1y3dvF2dHXXi3qvbBw3UnD/0vQxXjwyqOHlTVdrjl8/dCh+tVtW+afbE4u/6Pf1LVHpLqUeUdnV5xNuLUfaRJxtAYcdYkyLMAMPbr8tmLMeN1vw9fPG2eOFtSO0ZV+4rOA6r8/es+FGejhI9rx4Q98n2fnX2eqrYvS36bOzrkM+wiHbLHTZ4BERGRFWxARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRVsQEREZEWfHcUTCrbD6ZSNqnnxlXXiui63bgRKZ4d8XE56RoeqdgbSxdnqw3tUtf/j5hvF2UjdLlXtH294VZWf8pU2cdZfP1hV++ieveLsc288p6q979C74uyIQYp5QwBih96hyv/5uQ3ibPGR36hqJzS1i7PeQfJ9CQAxJkGcfX+HbpTVhAsmibONDfLRVABw4ECVKp+eJh9RVFvXrKpdXl4izlaUb1XV1pyBOBThzrBsdBjPgIiIyAo2ICIisoINiIiIrGADIiIiK9iAiIjICjYgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKCDYiIiKzos7PgYhMdcLkcouzhwwFx3ZTBKap1pCTHi7OzM4aral83NVec3Thsv6r282+8Kc7u2a+rnZAjnx0GAIMHyefvRdUeVNUectP/EWfvvXaMqvZRv3w2mduZqapd+rpuNtnyHa+Ls65ol6r2nPPkDwO/ffNvqtpJyani7I6KWl3tbcXi7MisiKr26m1BVT5vRJo4W+25QFW7pVM+Oy4pXvaYeUx8rDxrQvL7cUcnZ8EREVEfxgZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVvTZUTyBliCcLtlIkWiffETE0RbdqJcEX5w4e0Xu5aracVHysRnBJvlYGAC4deZMcfa887JUta9/+j5V/u8fNomzUybK9yUANIYniLNvb/tAVTtdMdJm7DD5NgLAy1ueUOUDzsHibHzEr6rtS3aLs837dGN+nPUHxNnsjBhV7be3y0fUROmmR2GqfIIQACDQdEScHZWqO8YDrmHirP9wlap2mz8szsa45ecrnWHZYxvPgIiIyAo2ICIiskLdgDZv3owrr7wSmZmZcDgcWLduXbfrb7zxRjgcjm6XuXPn9tR6iYhogFA3oJaWFkyePBnLli07YWbu3LmoqanpurzwwguntUgiIhp41C9CmDdvHubNm/elGa/Xi/T09FNeFBERDXy98hzQpk2bkJqairFjx+L2229HQ0PDCbOhUAiBQKDbhYiIBr4eb0Bz587Fs88+i40bN+LnP/85iouLMW/ePITDx3+5X1FREXw+X9clOzu7p5dERER9UI+/D+jaa6/t+vekSZOQm5uLUaNGYdOmTZh5nPemFBYWYsmSJV1fBwIBNiEiorNAr78Me+TIkUhJSUF5eflxr/d6vUhMTOx2ISKiga/XG9CBAwfQ0NCAjIyM3v5RRETUj6j/BNfc3NztbKaiogKlpaVITk5GcnIyHnnkESxYsADp6enYu3cv7r33XowePRpz5szp0YUTEVH/pm5A27dvx6WXXtr19bHnbxYtWoTly5dj586d+P3vf4/GxkZkZmZi9uzZ+PGPfwyv16v6OXGJDriEs9K8ngRx3U/36WZ2NTUPEmdXrHpRVfvOf/umOPtB1aeq2nWQr/s3uzerau/eL58fBQApvlhxtqnNp6pddMMPxdnv/cf1qtqeGPmsPkeHbtjYmIwWVf7J9fHi7Ojhuj9s7P9EPmdwZKLufryjVv4n9bhQRFV7SHKyOFt5RPdQFxfTqMofbuwUZ5Pb/qhbi1N+u4RjJ6tqH2lJEWdDzUH5OsKy20PdgGbMmAFjzAmvf/3117UliYjoLMRZcEREZAUbEBERWcEGREREVrABERGRFWxARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnR458H1FPi4p1wRcn6Y+NRv7hu1mC3ah01VY3i7Iupuvle/3jiZXH2wskTVLX3VtaIswdaSlW1k+JDqrwX8tv87u/8XlV7SEeVOBs3SD47DACGpdeLs/UB+SwwADjYpLvr3TBPPiNv18fy+wMAvFUm358+p247Pz7aJs7mnqubBfdJvfy4So9qVNWuduu289Lzo8XZd0t1tTNS5DMJxybuU9WOzzj+x+Qcz4ay88VZA9m8SJ4BERGRFWxARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRVsQEREZEWfHcWTnNCKKLesPx46HBDXTUgdrlpHTEQ+1iTYrLs5H/neQ+Lstx+4RVW7I2WwOJubGq+qvbtWPhYGAN79ze/E2ff/uk5V+9KvJImzddXtqtrfHCMfDbO5MlFVe/ok3TiWJn+tOHv0iGwMyjEOp1ecrQ3rbsOxY+Qjahr8raraF4wNirPvlxtV7YxE3cguf1C+9osme1S1//yh/DhM9Opuw6MR+ZiffxmzTZwNdhjsLj15jmdARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVjiMMbohSb0sEAjA5/PBmxwFh1M2p+j8C7LF9T/6tE21HkdQPsuq6fAhVe3fLFkhzlYd/ERV+51/vCTO1h3SzbB753c/V+XjDu8WZ8v271DVjvXIZ5NtfkdX+/nSenHWnaibv/bJgSOq/J3fThJnUzwJqtov/fWoOPtpg24W3IhMef5gY4qqdjDUJM7W1eke5s4Zo5vVV1Mtnx3nGxRS1Y645I9BgxOSVLWjnfI5ms0B+THeGTbYWtoOv9+PxMQTz0nkGRAREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVrABERGRFWxARERkBRsQERFZwQZERERW6GawnEGxqZ1wuGTZGHwqrhsdm6laR8TIxgEBQOqwNFXtEedOEWd3fPCuqjZMqjj69spCVemouvdVefdw+YgV1/u6ETX/tVm+lnGZyaraecPl+/6jZvlIEwBocSSp8n//WD5KpuLTOlVtuOLF0SFxzarSl0yV39+e/YtulNXBOvm6MzJiVbUd0bpxOW1R8t/lmw/JRwgBgDfaI87urdLVnnSOfISQUbSLMAyAk49h4hkQERFZoWpARUVFmDp1KhISEpCamoqrrroKZWVl3TLBYBAFBQUYPHgw4uPjsWDBAtTVKX8jIyKiAU/VgIqLi1FQUICtW7fijTfeQEdHB2bPno2WlpauzF133YVXX30Va9asQXFxMaqrq3HNNdf0+MKJiKh/Uz0HtGHDhm5fr1y5EqmpqSgpKcH06dPh9/vxzDPPYNWqVbjssssAACtWrMC5556LrVu34oILLui5lRMRUb92Ws8B+f1+AEBy8mdP7paUlKCjowOzZs3qyowbNw7Dhg3Dli1bjlsjFAohEAh0uxAR0cB3yg0oEongzjvvxIUXXoiJEycCAGpra+HxeJCUlNQtm5aWhtra2uPWKSoqgs/n67pkZ8s/XI6IiPqvU25ABQUF2LVrF1avXn1aCygsLITf7++6VFVVnVY9IiLqH07pfUCLFy/G+vXrsXnzZmRlZXV9Pz09He3t7WhsbOx2FlRXV4f09PTj1vJ6vfB6vaeyDCIi6sdUZ0DGGCxevBhr167FW2+9hZycnG7XT5kyBW63Gxs3buz6XllZGSorK5Gfn98zKyYiogFBdQZUUFCAVatW4ZVXXkFCQkLX8zo+nw8xMTHw+Xy4+eabsWTJEiQnJyMxMRF33HEH8vPz+Qo4IiLqRtWAli9fDgCYMWNGt++vWLECN954IwDgiSeegNPpxIIFCxAKhTBnzhw89dRTPbJYIiIaOBzGGPmQqTMgEAjA5/MheWgGnE7ZXwjdvoPi+imDxqjWs7dcPpsscZDupvx/Pzv+S9OP550331bVnpsrnx/15nu6+WtLropW5be9+ao4e/CIrnajkc/4SkqVz8cDgMDBF8XZj+t1625o081Uq2uOiLNh5UuLDgXk88Dik3VTTS7KHSTOvvOu7japbuwQZ2t0I9Iw82u656Vr98mPrQM19araY86VH1vl+1Wl8ehV8hvmibfHirORcBiffvwx/H4/EhMTT5jjLDgiIrKCDYiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK9iAiIjICjYgIiKygg2IiIisOKWPYzgTrr5iGjwe2YiQtEFTxXVXv7ZStY7snLA462qXjzQBgKTa3eJsztBOVe1Dta3ibHRssqr2h9t1nwH1x23H/zDC49GMVwGAIT75CJSxkaOq2geD8g9HzEiPUdVurdONY8mMaxFnD7a1qWpHtTeIs41tLlXt17Y1irODlVPBfrjgxCNePu+5Et39p+KjkCo/JlP+OWaXnqv7vf+9SvntEuMKqmov3Sgf2RU2H4mzkbBszTwDIiIiK9iAiIjICjYgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKCDYiIiKxgAyIiIivYgIiIyAo2ICIisqLPzoKbOuZqxMTEirLr/3aPuG5DvXymFgCkpCSIs+Pd31DVfvPDg+Ls7K9mqmrHO5rF2dDhGlXtj48MVeWzs+PE2YbgAVXtc3O3irPVB0apapdVHRZnO7N1t0lqkm6mWun+gDh7pEk39ywqXj4PLDdDN2tsb6X8IaYpqJul+Pp2+fy9jij5bEQAWHCF7qHxrc3ymZELxqlKI3PkfHH27b+/pqo9epT88e2NXdHibDgcAVBx0hzPgIiIyAo2ICIisoINiIiIrGADIiIiK9iAiIjICjYgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKiz47ieWb9o4iKko0raTzaJK7bWt+hWkdW+tXirNNtVLXHZY8QZzsb5GN7AGDGAw+Ls5++fL+q9oHmear8HfcWirNtUUdVtT9tlN/mjmjdGJlBGSPF2eom+dgeAPA36UbDuNzx4mxMtO44DEZVi7N7q3UjhK76inzdjcGIqvb/FNeLs+f/q25M1k7/e6r81PPk+7NotV9VO961U5x9+7/WqGpfcPcN4mxcvE+cDXfKRhPxDIiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK9iAiIjICjYgIiKygg2IiIisYAMiIiIr2ICIiMiKPjsLLtjaCVeUbDbUvg+bxXXzJspnHwHA/qo94uxXv7FEVfuyi9PE2Zjk4araf4u5R5xtOSy//QDg1ef/W5WfeUmVOPuJbkwWNn8on+2X465R1Ta+dnE2Nmaoqnayw63KH2yqEGdbTayqdptiLN2okVmq2q99VCnO1tfK5ocdMygrWpytrjykqr17l25m5FtN8hl5V1wxU1W7vkQ+H9FED1bVbqpqEWcPGPm+NBHZPEKeARERkRWqBlRUVISpU6ciISEBqampuOqqq1BWVtYtM2PGDDgcjm6X2267rUcXTURE/Z+qARUXF6OgoABbt27FG2+8gY6ODsyePRstLd1P42655RbU1NR0XR5//PEeXTQREfV/queANmzY0O3rlStXIjU1FSUlJZg+fXrX92NjY5Gent4zKyQiogHptJ4D8vs/e8Y4OTm52/eff/55pKSkYOLEiSgsLERr64mf5QyFQggEAt0uREQ08J3yq+AikQjuvPNOXHjhhZg4cWLX96+//noMHz4cmZmZ2LlzJ+677z6UlZXh5ZdfPm6doqIiPPLII6e6DCIi6qdOuQEVFBRg165deOedd7p9/9Zbb+3696RJk5CRkYGZM2di7969GDVq1BfqFBYWYsmSf758ORAIIDs7+1SXRURE/cQpNaDFixdj/fr12Lx5M7Kyvvx9AXl5eQCA8vLy4zYgr9cLr9d7KssgIqJ+TNWAjDG44447sHbtWmzatAk5OTkn/T+lpaUAgIyMjFNaIBERDUyqBlRQUIBVq1bhlVdeQUJCAmprawEAPp8PMTEx2Lt3L1atWoWvf/3rGDx4MHbu3Im77roL06dPR25ubq9sABER9U+qBrR8+XIAn73Z9H9bsWIFbrzxRng8Hrz55ptYunQpWlpakJ2djQULFuBHP/pRjy2YiIgGBvWf4L5MdnY2iouLT2tBxwzrnAy3kc3LGjLpcnHdhqPyuWQA0BqSz0pCp+4l5FHhTHHWEelU1R6UKZ8d9/5zd6lqD0/NU+V/u082FwoAJuT4VLXjk+Qzu4Zn6Z5rDB2R7889R1JUtetddar8yHT5OyYO7A6pag9JlT8MHN6nm5EWN8gjzvqVM+zq6+UzDKeN1c3ey82drMp7IvK1hHGeqvbFN48WZ4+06OYdtrXL5m0CwKAhieJsJBxB6+GTP3ZyFhwREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVrABERGRFWxARERkBRsQERFZwQZERERWnPLnAfW2hJQJ8LijRdnayn+I604Y+cWPhPgyKUdGiLPRvkZV7R/+5jlxNtTwkar2EwWDxdkjUe2q2v/57vE/XPBEGhIc4qz/I92ol/LqE3/a7ufVNjWpamcMlh1/ANDikK8DAPxHdaOVDnsPiLOD0iapanvijoqzLu8hVe3KOvmx1eGS394AEAzI89XVDaraY8aeo8pvL64WZ4eGPlHVPm/SBHH2//5umap2QvoIcdaXKD9fCXeGUY3DJ83xDIiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK9iAiIjICjYgIiKygg2IiIisYAMiIiIr2ICIiMiKPjsL7tJxPsR4ZbOerr7oanHdrSW6mWqXuj4UZ/OO7lfVPveGfHH2aG2KqnYk5BJnY5qDqtp1brcqf7hGXt8Tq5vXlpiQLs4mxOvmgSXEye8eh49WqGoHOwep8q0dceJseuZeVe0DR+Uz1VKidbP6ahp94uzwFI+qdlUgLM+W6WbYeaJ1+6ct5BdnWzy62mv/a4M4OzRdPjMQAC6Z911xdtd7j4mzDqcR5XgGREREVrABERGRFWxARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRV9dhRPa7ANJiIb53D9RRFx3QmZQ1Xr+M2Tr4uzF44ep6qNJvmImobqOlXpt/96WJx9dV+8qrY3QT52BABiQg55NkE+cgYAPLHN4mxijO5w33MgIM4GQ7rbsEU5/ijjXHn96n3yfQ8AiJKPbaptS1aVdkfJRys1dMqPEwBITpWPBUpxyfclAETqK1X5+NrB4mwwrVFV2xMlH31VWXOOqva3Z8jvE50TLhVnO9o7sPPvr540xzMgIiKygg2IiIisYAMiIiIr2ICIiMgKNiAiIrKCDYiIiKxgAyIiIivYgIiIyAo2ICIisoINiIiIrGADIiIiK/rsLLg1b/wPopyyGVXfmvJNcd0/V45SrSOcfZ44e9+ONlXt+xL2iLMTMgapaufU+MTZvfUfqWonpcWq8lFt8t9zag7rficKtsuzxqGbvzY+Sz4jrTWom2EHE1bFP61uFGeTB+lmqu0/JJ+lGGzXrRtG/hCTkyGfeQYAFfvlx8reRt3+cR+VzaE8Ztp0+bFyoEKeBYCQ4iCP9+hmEi5ds12czUpOEGc7OmVr5hkQERFZoWpAy5cvR25uLhITE5GYmIj8/Hy89tprXdcHg0EUFBRg8ODBiI+Px4IFC1BXp5viTEREZwdVA8rKysJjjz2GkpISbN++HZdddhnmz5+PDz/8EABw11134dVXX8WaNWtQXFyM6upqXHPNNb2ycCIi6t9UzwFdeeWV3b7+6U9/iuXLl2Pr1q3IysrCM888g1WrVuGyyy4DAKxYsQLnnnsutm7digsuuKDnVk1ERP3eKT8HFA6HsXr1arS0tCA/Px8lJSXo6OjArFmzujLjxo3DsGHDsGXLlhPWCYVCCAQC3S5ERDTwqRvQBx98gPj4eHi9Xtx2221Yu3Ytxo8fj9raWng8HiQlJXXLp6Wloba29oT1ioqK4PP5ui7Z2dnqjSAiov5H3YDGjh2L0tJSbNu2DbfffjsWLVqE3bt3n/ICCgsL4ff7uy5VVVWnXIuIiPoP9fuAPB4PRo8eDQCYMmUK3nvvPfzqV7/CwoUL0d7ejsbGxm5nQXV1dUhPTz9hPa/XC6/Xq185ERH1a6f9PqBIJIJQKIQpU6bA7XZj48aNXdeVlZWhsrIS+fn5p/tjiIhogFGdARUWFmLevHkYNmwYmpqasGrVKmzatAmvv/46fD4fbr75ZixZsgTJyclITEzEHXfcgfz8fL4CjoiIvkDVgA4dOoTvfOc7qKmpgc/nQ25uLl5//XVcfvnlAIAnnngCTqcTCxYsQCgUwpw5c/DUU0+d0sIONwfgEo7iueutFHHdS67IVa1jceC34mxd3Q5V7SRzvjh7z4ZhqtpZoRJxNirzPFXt2sMVqry/rUmcTU7WjRw66m8QZz1RaaraDe3y0UrJnmhVbWf6flU+a9gEcTYurkZV+72yGHE2NUs3hmnsEPkYmW3FzaraSWmK0T0Rj6r22FG62/BvW6rF2THDMlS1jZEfWy6XbsxPS1A+nurjyhZxNhzpEOVUDeiZZ5750uujo6OxbNkyLFu2TFOWiIjOQpwFR0REVrABERGRFWxARERkBRsQERFZwQZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFaop2H3NmMMACAciYj/T7tiZEpbq27cR3OoU5xt6TS9Vru9Qz7SBACCnWFxNhyWZwEgEpbvGwAwYfntoq4d6b3aEcW6w0ZZW3eooLNDvo86OnTFjeK+FlEcVwDQ2SGvbbS3oWJ/arYRADqV9+Vjj1sS4bBsTM0/8/LxOuGw7nFCsxYjHK8D/HMUz8luF4fR3HJnwIEDB/ihdEREA0BVVRWysrJOeH2fa0CRSATV1dVISEiAw+Ho+n4gEEB2djaqqqqQmJhocYW9i9s5cJwN2whwOweanthOYwyampqQmZkJp/PEz/T0uT/BOZ3OL+2YiYmJA3rnH8PtHDjOhm0EuJ0Dzelup8/nO2mGL0IgIiIr2ICIiMiKftOAvF4vHnroIXi9XttL6VXczoHjbNhGgNs50JzJ7exzL0IgIqKzQ785AyIiooGFDYiIiKxgAyIiIivYgIiIyIp+04CWLVuGESNGIDo6Gnl5eXj33XdtL6lHPfzww3A4HN0u48aNs72s07J582ZceeWVyMzMhMPhwLp167pdb4zBgw8+iIyMDMTExGDWrFnYs2ePncWehpNt54033viFfTt37lw7iz1FRUVFmDp1KhISEpCamoqrrroKZWVl3TLBYBAFBQUYPHgw4uPjsWDBAtTV1Vla8amRbOeMGTO+sD9vu+02Sys+NcuXL0dubm7Xm03z8/Px2muvdV1/pvZlv2hAL774IpYsWYKHHnoI77//PiZPnow5c+bg0KFDtpfWoyZMmICampquyzvvvGN7SaelpaUFkydPxrJly457/eOPP45f//rXePrpp7Ft2zbExcVhzpw5CAaDZ3ilp+dk2wkAc+fO7bZvX3jhhTO4wtNXXFyMgoICbN26FW+88QY6Ojowe/ZstLS0dGXuuusuvPrqq1izZg2Ki4tRXV2Na665xuKq9STbCQC33HJLt/35+OOPW1rxqcnKysJjjz2GkpISbN++HZdddhnmz5+PDz/8EMAZ3JemH5g2bZopKCjo+jocDpvMzExTVFRkcVU966GHHjKTJ0+2vYxeA8CsXbu26+tIJGLS09PNL37xi67vNTY2Gq/Xa1544QULK+wZn99OY4xZtGiRmT9/vpX19JZDhw4ZAKa4uNgY89m+c7vdZs2aNV2Zjz76yAAwW7ZssbXM0/b57TTGmEsuucR8//vft7eoXjJo0CDz29/+9ozuyz5/BtTe3o6SkhLMmjWr63tOpxOzZs3Cli1bLK6s5+3ZsweZmZkYOXIkbrjhBlRWVtpeUq+pqKhAbW1tt/3q8/mQl5c34PYrAGzatAmpqakYO3Ysbr/9djQ0NNhe0mnx+/0AgOTkZABASUkJOjo6uu3PcePGYdiwYf16f35+O495/vnnkZKSgokTJ6KwsBCtra02ltcjwuEwVq9ejZaWFuTn55/RfdnnhpF+Xn19PcLhMNLS0rp9Py0tDR9//LGlVfW8vLw8rFy5EmPHjkVNTQ0eeeQRXHzxxdi1axcSEhJsL6/H1dbWAsBx9+ux6waKuXPn4pprrkFOTg727t2LH/zgB5g3bx62bNkCl0v+WS99RSQSwZ133okLL7wQEydOBPDZ/vR4PEhKSuqW7c/783jbCQDXX389hg8fjszMTOzcuRP33XcfysrK8PLLL1tcrd4HH3yA/Px8BINBxMfHY+3atRg/fjxKS0vP2L7s8w3obDFv3ryuf+fm5iIvLw/Dhw/HSy+9hJtvvtniyuh0XXvttV3/njRpEnJzczFq1Chs2rQJM2fOtLiyU1NQUIBdu3b1++coT+ZE23nrrbd2/XvSpEnIyMjAzJkzsXfvXowaNepML/OUjR07FqWlpfD7/fjDH/6ARYsWobi4+Iyuoc//CS4lJQUul+sLr8Coq6tDenq6pVX1vqSkJJxzzjkoLy+3vZRecWzfnW37FQBGjhyJlJSUfrlvFy9ejPXr1+Ptt9/u9rEp6enpaG9vR2NjY7d8f92fJ9rO48nLywOAfrc/PR4PRo8ejSlTpqCoqAiTJ0/Gr371qzO6L/t8A/J4PJgyZQo2btzY9b1IJIKNGzciPz/f4sp6V3NzM/bu3YuMjAzbS+kVOTk5SE9P77ZfA4EAtm3bNqD3K/DZp/42NDT0q31rjMHixYuxdu1avPXWW8jJyel2/ZQpU+B2u7vtz7KyMlRWVvar/Xmy7Tye0tJSAOhX+/N4IpEIQqHQmd2XPfqShl6yevVq4/V6zcqVK83u3bvNrbfeapKSkkxtba3tpfWYf//3fzebNm0yFRUV5m9/+5uZNWuWSUlJMYcOHbK9tFPW1NRkduzYYXbs2GEAmF/+8pdmx44dZv/+/cYYYx577DGTlJRkXnnlFbNz504zf/58k5OTY9ra2iyvXOfLtrOpqcncfffdZsuWLaaiosK8+eab5vzzzzdjxowxwWDQ9tLFbr/9duPz+cymTZtMTU1N16W1tbUrc9ttt5lhw4aZt956y2zfvt3k5+eb/Px8i6vWO9l2lpeXm0cffdRs377dVFRUmFdeecWMHDnSTJ8+3fLKde6//35TXFxsKioqzM6dO839999vHA6H+ctf/mKMOXP7sl80IGOMefLJJ82wYcOMx+Mx06ZNM1u3brW9pB61cOFCk5GRYTwejxk6dKhZuHChKS8vt72s0/L2228bAF+4LFq0yBjz2UuxH3jgAZOWlma8Xq+ZOXOmKSsrs7voU/Bl29na2mpmz55thgwZYtxutxk+fLi55ZZb+t0vT8fbPgBmxYoVXZm2tjbzve99zwwaNMjExsaaq6++2tTU1Nhb9Ck42XZWVlaa6dOnm+TkZOP1es3o0aPNPffcY/x+v92FK333u981w4cPNx6PxwwZMsTMnDmzq/kYc+b2JT+OgYiIrOjzzwEREdHAxAZERERWsAEREZEVbEBERGQFGxAREVnBBkRERFawARERkRVsQEREZAUbEBERWcEGREREVrABERGRFWxARERkxf8HM2xSKyAZ0VcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_img2(file_path):\n",
    "    \"\"\" img = tf.io.read_file(f\"D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\data\\\\images\\\\{file_path}\") \"\"\"\n",
    "    image_string = tf.compat.as_str_any(file_path)\n",
    "    img = tf.io.read_file(file_path)    \n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [WIDTH,HEIGHT])      \n",
    "    return img\n",
    "\n",
    "img2 = process_img2(\"D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\result.jpg\")\n",
    "\n",
    "\"\"\" # Load the image\n",
    "img = tf.io.read_file(\"D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\template.jpg\")\n",
    "img = tf.image.decode_jpeg(img, channels=3)\n",
    "img = tf.image.resize(img, (256, 256))\n",
    "img = tf.keras.applications.resnet50.preprocess_input(img) \"\"\"\n",
    "\n",
    "# Get the prediction\n",
    "prediction = model.predict(img2[tf.newaxis, ...])\n",
    "\n",
    "# Print the prediction\n",
    "print(prediction)\n",
    "plt.imshow(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' files_ds = tf.data.Dataset.from_tensor_slices((train_bw[i], train_color[i])) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" files_ds = tf.data.Dataset.from_tensor_slices((dtrain['ImageFile'], sco_arr))\n",
    "files_ds = files_ds.map(lambda x, y: (process_img(x), y)).batch(1)\n",
    "print(files_ds) \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(files_ds,epochs=2, verbose=1)  \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" files_ds = tf.data.Dataset.from_tensor_slices((aaa, sco_arr))\n",
    "files_ds = files_ds.map(lambda x, y: (x, y)).batch(1) \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(files_ds,epochs=2, verbose=1) \"\"\"\n",
    "\"\"\" dtrain = pd.read_csv('D:\\\\OneDrive\\\\Desktop\\\\machine-2\\\\data\\\\train.csv', encoding='latin-1') \"\"\"\n",
    "\"\"\" model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(256,256,3)))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='softmax')) \"\"\"\n",
    "\n",
    "    # Compile and train the model\n",
    "\"\"\" model.compile(optimizer='adam', loss='MSE', metrics=['accuracy'])\n",
    "    model.fit(dataset.batch(32), epochs=10) \"\"\"\n",
    "\"\"\" aaa = []\n",
    "    for number, i in enumerate(str_arr):\n",
    "        if number < 100:\n",
    "            aaa.append(process_img(i)) \"\"\"\n",
    "\"\"\" dtest = pd.read_csv('./data/test.csv', encoding='latin-1')  \"\"\"   \n",
    "\"\"\" files_ds = tf.data.Dataset((process_img(dtrain['ImageFile']), dtrain['score']))\n",
    "    files_ds = files_ds.map(lambda x, y: (x, y)).batch(1) \"\"\"\n",
    "\"\"\" files_ds = tf.data.Dataset.from_tensor_slices(dtrain['score'])\n",
    "    files_ds = files_ds.map(lambda x, y: (x, y)).batch(1)  \"\"\"\n",
    "\"\"\" val_files = tf.data.Dataset.from_tensor_slices((dtest['ImageFile'], dtest['score']))\n",
    "    val_files = val_files.map(lambda x, y: (process_img(x), tf.constant(y,dtype=tf.float32))).batch(2) \"\"\"\n",
    "\"\"\" model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(256,256,3)),\n",
    "    tf.keras.layers.Dense(784/2, activation='relu'),\n",
    "    tf.keras.layers.Dense(784/2, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "]) \n",
    "\"\"\"\n",
    "\"\"\" model = tf.keras.Sequential() \"\"\"\n",
    "\"\"\" model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(WIDTH, HEIGHT,3)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "        ]) \"\"\"\n",
    "\n",
    "\"\"\" model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(files_ds,epochs=2, verbose=1) \"\"\"\n",
    "\"\"\" files_ds = tf.data.Dataset.from_tensor_slices((train_bw[i], train_color[i])) \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cb0dd519e46c84f14fc2d0d6172fde6407ecb78b6d95b871c78761f2e6e52fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
