{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_ubyte\n",
    "import torch\n",
    "from sync_batchnorm import DataParallelWithCallback\n",
    "\n",
    "from modules.generator import OcclusionAwareGenerator\n",
    "from modules.keypoint_detector import KPDetector\n",
    "from animate import normalize_kp\n",
    "\n",
    "import ffmpeg\n",
    "from os.path import splitext\n",
    "from shutil import copyfileobj\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "\n",
    "opt = {\n",
    "    'config': '.\\\\first_order\\\\first-order-model\\\\config\\\\vox-256.yaml',\n",
    "    'checkpoint': '..\\\\first_order\\\\first-order-model\\\\checkpoint\\\\vox-cpk.pth.tar',\n",
    "    'driving_video':'.\\\\first_order\\\\final.mp4',\n",
    "    'source_image':  '.\\\\first_order\\\\result0.png',    \n",
    "    'result_video': '.\\\\result.mp4',\n",
    "    'relative': True,\n",
    "    'adapt_scale': True,\n",
    "    'find_best_frame': False,\n",
    "    'best_frame': None,\n",
    "    'cpu': False,\n",
    "    'audio': False,\n",
    "    'audio_on':False,\n",
    "    'size_video': 256,\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoints(config_path, checkpoint_path, cpu=False):\n",
    "\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.full_load(f)\n",
    "\n",
    "    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n",
    "                                        **config['model_params']['common_params'])\n",
    "    if not cpu:\n",
    "        generator.cuda()\n",
    "\n",
    "    kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
    "                             **config['model_params']['common_params'])\n",
    "    if not cpu:\n",
    "        kp_detector.cuda()\n",
    "\n",
    "    if cpu:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    kp_detector.load_state_dict(checkpoint['kp_detector'])\n",
    "\n",
    "    if not cpu:\n",
    "        generator = DataParallelWithCallback(generator)\n",
    "        kp_detector = DataParallelWithCallback(kp_detector)\n",
    "\n",
    "    generator.eval()\n",
    "    kp_detector.eval()\n",
    "\n",
    "    return generator, kp_detector\n",
    "\n",
    "\n",
    "def make_animation(source_image, driving_video, generator, kp_detector, relative=True, adapt_movement_scale=True, cpu=False):\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        source = torch.tensor(source_image[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n",
    "        if not cpu:\n",
    "            source = source.cuda()\n",
    "        driving = torch.tensor(np.array(driving_video)[np.newaxis].astype(np.float32)).permute(0, 4, 1, 2, 3)\n",
    "        kp_source = kp_detector(source)\n",
    "        kp_driving_initial = kp_detector(driving[:, :, 0])\n",
    "\n",
    "        for frame_idx in tqdm(range(driving.shape[2])):\n",
    "            driving_frame = driving[:, :, frame_idx]\n",
    "            if not cpu:\n",
    "                driving_frame = driving_frame.cuda()\n",
    "            kp_driving = kp_detector(driving_frame)\n",
    "            kp_norm = normalize_kp(kp_source=kp_source, kp_driving=kp_driving,\n",
    "                                   kp_driving_initial=kp_driving_initial, use_relative_movement=relative,\n",
    "                                   use_relative_jacobian=relative, adapt_movement_scale=adapt_movement_scale)\n",
    "            out = generator(source, kp_source=kp_source, kp_driving=kp_norm)\n",
    "\n",
    "            predictions.append(np.transpose(out['prediction'].data.cpu().numpy(), [0, 2, 3, 1])[0])\n",
    "    return predictions\n",
    "\n",
    "def find_best_frame(source, driving, cpu=False):\n",
    "    import face_alignment  # type: ignore (local file)\n",
    "    from scipy.spatial import ConvexHull\n",
    "\n",
    "    def normalize_kp(kp):\n",
    "        kp = kp - kp.mean(axis=0, keepdims=True)\n",
    "        area = ConvexHull(kp[:, :2]).volume\n",
    "        area = np.sqrt(area)\n",
    "        kp[:, :2] = kp[:, :2] / area\n",
    "        return kp\n",
    "\n",
    "    fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=True,\n",
    "                                      device='cpu' if cpu else 'cuda')\n",
    "    kp_source = fa.get_landmarks(255 * source)[0]\n",
    "    kp_source = normalize_kp(kp_source)\n",
    "    norm  = float('inf')\n",
    "    frame_num = 0\n",
    "    for i, image in tqdm(enumerate(driving)):\n",
    "        kp_driving = fa.get_landmarks(255 * image)[0]\n",
    "        kp_driving = normalize_kp(kp_driving)\n",
    "        new_norm = (np.abs(kp_source - kp_driving) ** 2).sum()\n",
    "        if new_norm < norm:\n",
    "            norm = new_norm\n",
    "            frame_num = i\n",
    "    return frame_num\n",
    "\n",
    "def anti_img(img_frame):\n",
    "    img_frame = tf.convert_to_tensor(img_frame, dtype='float32')\n",
    "    img_frame = tf.image.resize(img_frame, size=(512, 512), antialias=True,method=tf.image.ResizeMethod.BILINEAR, preserve_aspect_ratio=False,)\n",
    "    return img_frame.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matheus\\AppData\\Local\\Temp\\ipykernel_23544\\2952144168.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  source_image = imageio.imread(opt['source_image'])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'f:\\video_g\\first_order\\first-order-model\\first_order\\result0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mTrue\u001b[39;00m:   \n\u001b[1;32m----> 3\u001b[0m     source_image \u001b[39m=\u001b[39m imageio\u001b[39m.\u001b[39;49mimread(opt[\u001b[39m'\u001b[39;49m\u001b[39msource_image\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      4\u001b[0m     reader \u001b[39m=\u001b[39m imageio\u001b[39m.\u001b[39mget_reader(opt[\u001b[39m'\u001b[39m\u001b[39mdriving_video\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m     fps \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39mget_meta_data()[\u001b[39m'\u001b[39m\u001b[39mfps\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\imageio\\__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[39mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     90\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m     95\u001b[0m )\n\u001b[1;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m imread_v2(uri, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\imageio\\v2.py:226\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m imopen_args \u001b[39m=\u001b[39m decypher_format_arg(\u001b[39mformat\u001b[39m)\n\u001b[0;32m    224\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mri\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    227\u001b[0m     result \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread(index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\imageio\\core\\imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     request\u001b[39m.\u001b[39mformat_hint \u001b[39m=\u001b[39m format_hint\n\u001b[0;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     request \u001b[39m=\u001b[39m Request(uri, io_mode, format_hint\u001b[39m=\u001b[39;49mformat_hint, extension\u001b[39m=\u001b[39;49mextension)\n\u001b[0;32m    115\u001b[0m source \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<bytes>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(uri, \u001b[39mbytes\u001b[39m) \u001b[39melse\u001b[39;00m uri\n\u001b[0;32m    117\u001b[0m \u001b[39m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\imageio\\core\\request.py:248\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Request.Mode: \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[39m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_uri(uri)\n\u001b[0;32m    250\u001b[0m \u001b[39m# Set extension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m extension \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\Pyflow\\lib\\site-packages\\imageio\\core\\request.py:408\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m is_read_request:\n\u001b[0;32m    406\u001b[0m     \u001b[39m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fn):\n\u001b[1;32m--> 408\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m fn)\n\u001b[0;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[39m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     dn \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(fn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'f:\\video_g\\first_order\\first-order-model\\first_order\\result0.jpg'"
     ]
    }
   ],
   "source": [
    "if True:   \n",
    "\n",
    "    source_image = imageio.imread(opt['source_image'])\n",
    "    reader = imageio.get_reader(opt['driving_video'])\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    driving_video = []\n",
    "    try:\n",
    "        for im in reader:\n",
    "            driving_video.append(im)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    reader.close()\n",
    "\n",
    "    source_image = resize(source_image, (opt['size_video'], opt['size_video']))[..., :3]\n",
    "    driving_video = [resize(frame, (opt['size_video'], opt['size_video']))[..., :3] for frame in driving_video]\n",
    "    generator, kp_detector = load_checkpoints(config_path=opt['config'], checkpoint_path=opt['checkpoint'], cpu=opt['cpu'])\n",
    "\n",
    "    if opt['find_best_frame'] or opt['best_frame'] is not None:\n",
    "        i = opt['best_frame'] if opt['best_frame'] is not None else find_best_frame(source_image, driving_video, cpu=opt['cpu'])\n",
    "        print (\"Best frame: \" + str(i))\n",
    "        driving_forward = driving_video[i:]\n",
    "        driving_backward = driving_video[:(i+1)][::-1]\n",
    "        predictions_forward = make_animation(source_image, driving_forward, generator, kp_detector, relative=opt['relative'], adapt_movement_scale=opt['adapt_scale'], cpu=opt['cpu'])\n",
    "        predictions_backward = make_animation(source_image, driving_backward, generator, kp_detector, relative=opt['relative'], adapt_movement_scale=opt['adapt_scale'], cpu=opt['cpu'])\n",
    "        predictions = predictions_backward[::-1] + predictions_forward[1:]\n",
    "    else:               \n",
    "        predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=opt['relative'], adapt_movement_scale=opt['adapt_scale'], cpu=opt['cpu'])\n",
    "    \n",
    "    # imageio.mimsave(opt['result_video'], [img_as_ubyte(anti_img(frame)) for frame in predictions], fps=fps)\n",
    "    imageio.mimsave(opt['result_video'], [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
    "\n",
    "    anti_img\n",
    "\n",
    "    if opt['audio']:\n",
    "        with NamedTemporaryFile(suffix='.' + splitext(opt['result_video'])[1]) as output:\n",
    "            ffmpeg.output(ffmpeg.input(opt['result_video']).video, ffmpeg.input(opt['driving_video']).audio, output.name, c='copy').run()\n",
    "            with open(opt['result_video'], 'wb') as result:\n",
    "                copyfileobj(output, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cb0dd519e46c84f14fc2d0d6172fde6407ecb78b6d95b871c78761f2e6e52fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
