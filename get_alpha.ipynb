{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process image: output_0245 (2).png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from MODNet.src.models.modnet import MODNet\n",
    "\n",
    "\n",
    "EXTERNAL = True\n",
    "\n",
    "\n",
    "\n",
    "input_path = 'F:/MODNet/MODNet/demo/image_matting/colab/input/output_0245 (2).png'\n",
    "output_path = 'F:/MODNet/MODNet/demo/image_matting/colab/output/out.png'\n",
    "ckpt_path = './models/modnet_photographic_portrait_matting.ckpt'\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.ckpt_path = ckpt_path\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# define hyper-parameters\n",
    "ref_size = 512\n",
    "\n",
    "# define image to tensor transform\n",
    "im_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create MODNet and load the pre-trained ckpt\n",
    "modnet = MODNet(backbone_pretrained=False)\n",
    "modnet = nn.DataParallel(modnet)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    modnet = modnet.cuda()\n",
    "    weights = torch.load(args.ckpt_path)\n",
    "else:\n",
    "    weights = torch.load(args.ckpt_path, map_location=torch.device('cpu'))\n",
    "modnet.load_state_dict(weights)\n",
    "modnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alpha(input_path_img, output_path_img):\n",
    "\n",
    "    im = Image.open(input_path_img)\n",
    "\n",
    "    # unify image channels to 3\n",
    "    im = np.asarray(im)\n",
    "    if len(im.shape) == 2:\n",
    "        im = im[:, :, None]\n",
    "    if im.shape[2] == 1:\n",
    "        im = np.repeat(im, 3, axis=2)\n",
    "    elif im.shape[2] == 4:\n",
    "        im = im[:, :, 0:3]\n",
    "\n",
    "    # convert image to PyTorch tensor\n",
    "    im = Image.fromarray(im)\n",
    "    im = im_transform(im)\n",
    "\n",
    "    # add mini-batch dim\n",
    "    im = im[None, :, :, :]\n",
    "\n",
    "    # resize image for input\n",
    "    im_b, im_c, im_h, im_w = im.shape\n",
    "    if max(im_h, im_w) < ref_size or min(im_h, im_w) > ref_size:\n",
    "        if im_w >= im_h:\n",
    "            im_rh = ref_size\n",
    "            im_rw = int(im_w / im_h * ref_size)\n",
    "        elif im_w < im_h:\n",
    "            im_rw = ref_size\n",
    "            im_rh = int(im_h / im_w * ref_size)\n",
    "    else:\n",
    "        im_rh = im_h\n",
    "        im_rw = im_w\n",
    "    \n",
    "    im_rw = im_rw - im_rw % 32\n",
    "    im_rh = im_rh - im_rh % 32\n",
    "    im = F.interpolate(im, size=(im_rh, im_rw), mode='area')\n",
    "\n",
    "    # inference\n",
    "    _, _, matte = modnet(im.cuda() if torch.cuda.is_available() else im, True)\n",
    "\n",
    "    # resize and save matte\n",
    "    matte = F.interpolate(matte, size=(im_h, im_w), mode='area')\n",
    "    matte = matte[0][0].data.cpu().numpy()\n",
    "    Image.fromarray(((matte * 255).astype('uint8')), mode='L').save(output_path_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_alpha(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cb0dd519e46c84f14fc2d0d6172fde6407ecb78b6d95b871c78761f2e6e52fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
